{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558dd966",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Initial Setup</h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd8943",
   "metadata": {},
   "source": [
    "Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cf4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import schwabdev\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import mplfinance as mpf\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "from Multi_Strat_Back_Tester_Functions import *\n",
    "from datetime import datetime, time\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9e360",
   "metadata": {},
   "source": [
    "Load environment variables from .env file for authentification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ed2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236f51a",
   "metadata": {},
   "source": [
    "Patches the notebook's running event loop so that it can handle multiple calls to `asyncio.run()` or other asynchronous methods without causing conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e17c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdd823",
   "metadata": {},
   "source": [
    "Set the display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ac27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display options\n",
    "# Set the global float format to 4 decimal places\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "pd.options.display.float_format = '{:,.4f}'.format # Format numerical output to have certain number of decimals\n",
    "# pd.options.display.float_format = None # Reset to default numerical output formatting\n",
    "pd.set_option('display.width', 2000) # Set the display width to a large number\n",
    "pd.set_option('display.max_colwidth', 1000) # Set max column width to a large number\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Displays all columns\n",
    "# pd.set_option('display.max_rows', None) # Displays all rows                             \n",
    "# pd.reset_option('display.max_columns') # Display default abbreviated columns\n",
    "pd.reset_option('display.max_rows') # Display default abbreviated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0361ac",
   "metadata": {},
   "source": [
    "Create the client object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5309e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App Key: 2C7Jh6zt5QdlSb0N5RnhWpaiEzKFr150\n",
      "App Secret: OQGxH0GkD5bAEMA4\n",
      "Callback URL: https://127.0.0.1\n",
      "The refresh token has expired, please update!\n",
      "Open to authenticate: https://api.schwabapi.com/v1/oauth/authorize?client_id=2C7Jh6zt5QdlSb0N5RnhWpaiEzKFr150&redirect_uri=https://127.0.0.1\n",
      "Client initialized!\n"
     ]
    }
   ],
   "source": [
    "app_key = os.getenv('app_key')\n",
    "app_secret = os.getenv('app_secret')\n",
    "callback_url = os.getenv('callback_url')\n",
    "\n",
    "# Print them to verify (avoid printing sensitive info in production)\n",
    "print(f\"App Key: {app_key}\")\n",
    "print(f\"App Secret: {app_secret}\")\n",
    "print(f\"Callback URL: {callback_url}\")\n",
    "\n",
    "# Now proceed to initialize the client\n",
    "client = schwabdev.Client(app_key, app_secret, callback_url)\n",
    "print('Client initialized!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f5ad1",
   "metadata": {},
   "source": [
    "Use this when in need of updating the refresh token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.update_tokens(force=True)\n",
    "# client = schwabdev.Client(app_key, app_secret, callback_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf52bd",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Permanent Data Extraction and Storage Functions</h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61f9d6",
   "metadata": {},
   "source": [
    "Ticker list and point value definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a957ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers = \"/ES,/NQ,/CL,/GC\"\n",
    "# tickers = \"MARA,PLUG,SOFI,SWN,RKLB\"\n",
    "\n",
    "ticker_to_point_value = {\n",
    "    \"/ES\": 50,       # E-Mini S&P 500\n",
    "    \"/NQ\": 20,       # E-Mini NASDAQ 100\n",
    "    \"/CL\": 1000,     # Crude Oil\n",
    "    \"/GC\": 100,      # Gold\n",
    "}\n",
    "\n",
    "ticker_to_tick_size = {\n",
    "    \"/ES\": 0.25,        # E-Mini S&P 500\n",
    "    \"/NQ\": 0.25,        # E-Mini NASDAQ 100\n",
    "    \"/CL\": 0.01,        # Crude Oil\n",
    "    \"/GC\": 0.1,         # Gold\n",
    "}\n",
    "\n",
    "tick_size = ticker_to_tick_size.get(\"/ES\")\n",
    "tick_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers = \"/ES,/NQ,/CL,/GC,/MES,/MNQ,/MCL,/MGC\"\n",
    "# # tickers = \"MARA,PLUG,SOFI,SWN,RKLB\"\n",
    "\n",
    "# ticker_to_point_value = {\n",
    "#     \"/ES\": 50,       # E-Mini S&P 500\n",
    "#     \"/NQ\": 20,       # E-Mini NASDAQ 100\n",
    "#     \"/CL\": 1000,     # Crude Oil\n",
    "#     \"/GC\": 100,      # Gold\n",
    "#     \"/MES\": 5,       # Micro E-Mini S&P 500\n",
    "#     \"/MNQ\": 2,       # Micro E-Mini NASDAQ 100\n",
    "#     \"/MCL\": 100,     # Micro Crude Oil\n",
    "#     \"/MGC\": 10       # Micro Gold\n",
    "# }\n",
    "\n",
    "# ticker_to_tick_size = {\n",
    "#     \"/ES\": 0.25,        # E-Mini S&P 500\n",
    "#     \"/NQ\": 0.25,        # E-Mini NASDAQ 100\n",
    "#     \"/CL\": 0.01,        # Crude Oil\n",
    "#     \"/GC\": 0.1,         # Gold\n",
    "#     \"/MES\": 0.25,       # Micro E-Mini S&P 500\n",
    "#     \"/MNQ\": 0.25,       # Micro E-Mini NASDAQ 100\n",
    "#     \"/MCL\": 0.01,       # Micro Crude Oil\n",
    "#     \"/MGC\": 0.1         # Micro Gold\n",
    "# }\n",
    "\n",
    "# tick_size = ticker_to_tick_size.get(\"/ES\")\n",
    "# tick_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e0586",
   "metadata": {},
   "source": [
    "Extracting and storing raw streaming data with two functions into ticker_tables dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_row_data(entry, content):\n",
    "    \n",
    "    # Create a row dictionary with the relevant fields\n",
    "    row = { # For futures\n",
    "        'timestamp': entry['timestamp'],\n",
    "        'key': content.get('key', None),\n",
    "        'bid_price': content.get('1', None),\n",
    "        'ask_price': content.get('2', None),\n",
    "        # 'last_price': last_price,  # Use updated last_price\n",
    "        'last_price': content.get('3', None),\n",
    "        'bid_size': content.get('4', None), # These two variables can be correlated \n",
    "        'ask_size': content.get('5', None), # with direction of price action\n",
    "        'total_volume': content.get('8', None),\n",
    "        'last_size': content.get('9', 0),\n",
    "        'high_price': content.get('12', None),\n",
    "        'low_price': content.get('13', None),\n",
    "        'close_price': content.get('14', None),\n",
    "        'open_price': content.get('18', None),\n",
    "        'net_change': content.get('19', None),\n",
    "        'future_pct_change': content.get('20', None),\n",
    "        'open_interest': content.get('23', None),\n",
    "        'tick': content.get('25', None),\n",
    "        'tick_amount': content.get('26', None),\n",
    "        'future_exp_date': content.get('35', None),\n",
    "        'ask_time': content.get('37', None),\n",
    "        'bid_time': content.get('38', None)\n",
    "        }\n",
    "\n",
    "    # row = { # For equities\n",
    "    #     'timestamp': entry['timestamp'],               # Same\n",
    "    #     'key': content.get('key', None),               # Same\n",
    "    #     'bid_price': content.get('1', None),           # Matches bid_price\n",
    "    #     'ask_price': content.get('2', None),           # Matches ask_price\n",
    "    #     'last_price': last_price,                      # Matches last_price (updated)\n",
    "    #     'bid_size': content.get('4', None),            # Matches bid_size\n",
    "    #     'ask_size': content.get('5', None),            # Matches ask_size\n",
    "    #     'total_volume': content.get('8', None),        # Matches total_volume\n",
    "    #     'last_size': content.get('9', 0),              # Matches last_size\n",
    "    #     'high_price': content.get('10', None),         # Matches high_price\n",
    "    #     'low_price': content.get('11', None),          # Matches low_price\n",
    "    #     'close_price': content.get('12', None),        # Matches close_price\n",
    "    #     'open_price': content.get('17', None),         # Matches open_price\n",
    "    #     'net_change': content.get('18', None),         # Matches net_change\n",
    "    #     '52_week_high': content.get('19', None),       # Matches 52_week_high\n",
    "    #     '52_week_low': content.get('20', None),        # Matches 52_week_low\n",
    "    #     'pe_ratio': content.get('21', None),           # Matches pe_ratio\n",
    "    #     'net_pct_change': content.get('42', None)}      # Matches net_pct_change  \n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a33b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_tables = 'nothing'\n",
    "ticker_tables = {ticker: pd.DataFrame() for ticker in tickers.split(\",\")}\n",
    "\n",
    "# Initialize a dictionary to store the last known price for each ticker\n",
    "last_known_price = {ticker: None for ticker in tickers.split(\",\")}\n",
    "\n",
    "def process_message_data(data):\n",
    "    global ticker_tables, last_known_price\n",
    "    \n",
    "    # Loop through the content and extract the relevant fields\n",
    "    if \"data\" in data:\n",
    "        for entry in data['data']:\n",
    "            if 'content' in entry:\n",
    "                for content in entry['content']:\n",
    "                    # Extract row data\n",
    "                    row = extract_row_data(entry, content)\n",
    "\n",
    "                    # Get the ticker (key) and last_price\n",
    "                    ticker = row['key']\n",
    "                    last_price = row.get('last_price')\n",
    "\n",
    "                    # Check if last_price is None, if so use the last known price for the ticker\n",
    "                    if last_price is None and ticker in last_known_price:\n",
    "                        row['last_price'] = last_known_price[ticker]\n",
    "                    else:\n",
    "                        # Update the last known price\n",
    "                        last_known_price[ticker] = last_price\n",
    "\n",
    "                    # Convert the row dictionary to a DataFrame\n",
    "                    row_df = pd.DataFrame([row])\n",
    "\n",
    "                    # Check the ticker and append the row to the correct ticker table\n",
    "                    if ticker in ticker_tables:\n",
    "                        ticker_tables[ticker] = pd.concat([ticker_tables[ticker], row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7edb29",
   "metadata": {},
   "source": [
    "Compressing minute candles from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_candles = 'nothing'\n",
    "minute_candles = {ticker: pd.DataFrame(columns=['datetime', 'ticker', 'open', 'high', 'low', 'close', 'accumulative_volume']) for ticker in tickers.split(\",\")}\n",
    "\n",
    "def update_minute_candles(ticker_tables, time_frame='min'):\n",
    "    global minute_candles\n",
    "\n",
    "    for ticker, df in ticker_tables.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Ensure that 'datetime' column exists and is properly set\n",
    "        if 'timestamp' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True).dt.tz_convert('US/Eastern')\n",
    "\n",
    "        # Ensure that the 'datetime' column is set as the DataFrame index (only if not already set)\n",
    "        if df.index.name != 'datetime':\n",
    "            df.set_index('datetime', inplace=True)\n",
    "\n",
    "        # Group the data by minute intervals using 'min'\n",
    "        current_minute = df.index.floor(time_frame)[-1]  # Get the most recent minute\n",
    "\n",
    "        # Select only the rows from the most recent minute\n",
    "        recent_data = df[df.index.floor(time_frame) == current_minute]\n",
    "\n",
    "        if not recent_data.empty:\n",
    "            # Extract OHLC values for the minute candle\n",
    "            open_price = recent_data['last_price'].iloc[0]  # Open is the first last_price\n",
    "            high_price = recent_data['last_price'].max()     # High is the max last_price\n",
    "            low_price = recent_data['last_price'].min()      # Low is the min last_price\n",
    "            close_price = recent_data['last_price'].iloc[-1] # Close is the last last_price\n",
    "            total_volume = recent_data['total_volume'].max() # Total volume is the max value in this interval\n",
    "\n",
    "            # Create a dictionary with the new candle data\n",
    "            new_candle = {\n",
    "                'datetime': current_minute,\n",
    "                'ticker': ticker,\n",
    "                'open': open_price,\n",
    "                'high': high_price,\n",
    "                'low': low_price,\n",
    "                'close': close_price,\n",
    "                'accumulative_volume': total_volume\n",
    "            }\n",
    "\n",
    "            # Convert the dictionary to a DataFrame and update the respective ticker's DataFrame in minute_candles\n",
    "            new_candle_df = pd.DataFrame([new_candle])\n",
    "\n",
    "            # Replace or append the most recent candle for this ticker\n",
    "            if not minute_candles[ticker].empty and minute_candles[ticker]['datetime'].iloc[-1] == current_minute:\n",
    "                minute_candles[ticker].iloc[-1] = new_candle  # Update the last candle\n",
    "            else:\n",
    "                minute_candles[ticker] = pd.concat([minute_candles[ticker], new_candle_df], ignore_index=True)  # Append new candle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d00e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new nested dictionary\n",
    "compressed_sessions = {}\n",
    "\n",
    "def compress_candles(candles, n):\n",
    "    \"\"\"\n",
    "    Compress candles for a given timeframe across a DataFrame.\n",
    "    Preserves time-derived columns if they exist.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): DataFrame containing the candle data.\n",
    "    - n (int): Number of minutes (rows) to compress into one candle.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A compressed DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(candles, pd.DataFrame) or n <= 0:\n",
    "        raise ValueError(\"Input must be a DataFrame, and 'n' must be a positive integer.\")\n",
    "\n",
    "    # Ensure sorted\n",
    "    candles = candles.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "    # Group every n rows\n",
    "    grouped = candles.groupby(candles.index // n)\n",
    "\n",
    "    # Columns to always aggregate\n",
    "    agg_dict = {\n",
    "        'datetime': 'first',\n",
    "        'ticker': 'first',\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'accumulative_volume': 'sum'\n",
    "    }\n",
    "\n",
    "    # Optionally preserve time-derived columns\n",
    "    for col in ['year', 'month', 'week', 'day', 'weekday', 'hour', 'minute']:\n",
    "        if col in candles.columns:\n",
    "            agg_dict[col] = 'first'\n",
    "\n",
    "    compressed = grouped.agg(agg_dict).reset_index(drop=True)\n",
    "\n",
    "    return compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a46bf1",
   "metadata": {},
   "source": [
    "A function that calculates a number of indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a4309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indicators_1(\n",
    "    df, \n",
    "    price_col='close', \n",
    "    acc_vol_col='accumulative_volume', \n",
    "    sma_periods=None, \n",
    "    wma_periods=None, \n",
    "    rsi_periods=None, \n",
    "    volume_col='volume', \n",
    "    candle_window=10, \n",
    "    base_window=5, \n",
    "    adaptive_window=3,\n",
    "    trend_window=6\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate technical indicators, including SMAs, WMAs, RSI, price action envelopes, and trend score.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the price data.\n",
    "    - price_col (str): The column name for the price data (default 'close').\n",
    "    - acc_vol_col (str): The column name for accumulative volume data (default 'accumulative_volume').\n",
    "    - sma_periods (list): A list of periods for SMAs.\n",
    "    - wma_periods (list): A list of periods for WMAs.\n",
    "    - rsi_periods (list): A list of periods for RSI.\n",
    "    - volume_col (str): The column name to store the volume difference (default 'volume').\n",
    "    - candle_window (int): The window size for candle metrics calculations (default 10).\n",
    "    - base_window (int): The window size for detecting local highs/lows in the price action envelope.\n",
    "    - adaptive_window (int): The alternative smaller window size for adaptive price action envelope.\n",
    "    - trend_window (int): The window size for calculating trend scores.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with calculated indicators.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure RSI periods is a valid list\n",
    "    if rsi_periods is None:\n",
    "        rsi_periods = []\n",
    "\n",
    "    # Calculate volume differences\n",
    "    df[volume_col] = df[acc_vol_col].diff()\n",
    "\n",
    "    # Calculate SMAs\n",
    "    if sma_periods:\n",
    "        for period in sma_periods:\n",
    "            df[f'sma_{period}'] = df[price_col].rolling(window=period).mean()\n",
    "\n",
    "    # Calculate WMAs\n",
    "    if wma_periods:\n",
    "        for period in wma_periods:\n",
    "            weights = np.arange(1, period + 1)  # Generate weights from 1 to the period length\n",
    "            df[f'wma_{period}'] = df[price_col].rolling(window=period).apply(\n",
    "                lambda prices: np.dot(prices, weights) / weights.sum(), raw=True\n",
    "            )\n",
    "\n",
    "    # calculate_vwap_and_bands(df, high_col='high', low_col='low', close_col='close', volume_col='volume')\n",
    "\n",
    "    # Calculate RSI\n",
    "    for period in rsi_periods:\n",
    "        delta = df[price_col].diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
    "        loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
    "        rs = gain / loss\n",
    "        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # # Calculate price action envelope (Updated with dynamic base_window & adaptive_window)\n",
    "    # df = calculate_price_action_envelope_1(df, high_col='high', low_col='low', base_window=base_window, adaptive_window=adaptive_window)\n",
    "\n",
    "    # # Calculate trend score (Added)\n",
    "    # df['trend_indicator'] = calculate_trend_score_1(df, open_col='open', high_col='high', low_col='low', close_col='close', window=trend_window)\n",
    "\n",
    "    # Calculate additional candle properties\n",
    "    df['ohlc_average'] = df[['open', 'high', 'low', 'close']].mean(axis=1)\n",
    "    df['candle_span'] = df['high'] - df['low']\n",
    "    df['candle_body'] = (df['close'] - df['open']).abs()\n",
    "    df['candle_span_avg'] = df['candle_span'].rolling(window=candle_window, min_periods=1).mean()\n",
    "    df['candle_span_max'] = df['candle_span'].rolling(window=candle_window, min_periods=1).max()\n",
    "    df['candle_span_maxavg_mean'] = (df['candle_span_avg'] + df['candle_span_max']) / 2\n",
    "\n",
    "    # Add constant reference lines for trend analysis\n",
    "    df['hundred_line'] = 100\n",
    "    df['fifty_line'] = 50\n",
    "    df['zero_line'] = 0\n",
    "    df['trend_high_threshold'] = 75\n",
    "    df['trend_low_threshold'] = 25\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c8cfa",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Trade Logic</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cd312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trading_signals_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Generate buy/sell signals based on moving averages and RSI indicators for either\n",
    "    a trend-following or mean-reversion strategy.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - strategy_type (str): 'trend' or 'reversion'.\n",
    "\n",
    "    Returns:\n",
    "    - candles (pd.DataFrame): The DataFrame with updated signal and position state columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Append strategy type to column names\n",
    "    ma_signal_column = f'signal_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_signal_column = f'signal_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_position_open_col = f'position_open_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_position_open_col = f'position_open_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Initialize columns\n",
    "    candles[ma_signal_column] = 0\n",
    "    candles[rsi_signal_column] = 0\n",
    "    candles[ma_position_open_col] = False\n",
    "    candles[rsi_position_open_col] = False\n",
    "\n",
    "    # ======= MOVING AVERAGE LOGIC =======\n",
    "    ma_position_open = True\n",
    "    ma_signals = []\n",
    "    ma_positions = []\n",
    "\n",
    "    for ma1, ma2 in zip(candles[ma_name1], candles[ma_name2]):\n",
    "        if strategy_type == 'trend':\n",
    "            # Trend-following logic\n",
    "            if ma_position_open and ma1 <= ma2: # if position is neutral and wma is below sma\n",
    "                ma_position_open = False\n",
    "                ma_signals.append(0)  # Neutral\n",
    "            elif not ma_position_open and ma1 > ma2:\n",
    "                ma_position_open = True\n",
    "                ma_signals.append(1)  # Long\n",
    "            else:\n",
    "                ma_signals.append(ma_signals[-1] if ma_signals else 0)\n",
    "        elif strategy_type == 'reversion':\n",
    "            # Mean-reversion logic (inverted)\n",
    "            if ma_position_open and ma1 > ma2:\n",
    "                ma_position_open = False\n",
    "                ma_signals.append(0)  # Neutral\n",
    "            elif not ma_position_open and ma1 <= ma2:\n",
    "                ma_position_open = True\n",
    "                ma_signals.append(1)  # Long\n",
    "            else:\n",
    "                ma_signals.append(ma_signals[-1] if ma_signals else 0)\n",
    "\n",
    "        ma_positions.append(ma_position_open)\n",
    "\n",
    "    candles[ma_signal_column] = ma_signals\n",
    "    candles[ma_position_open_col] = ma_positions\n",
    "\n",
    "    # ======= RSI LOGIC =======\n",
    "    rsi_position_open = True\n",
    "    rsi_signals = []\n",
    "    rsi_positions = []\n",
    "\n",
    "    for rsi in candles[rsi_column]:\n",
    "        if strategy_type == 'trend':\n",
    "            if rsi_position_open and rsi < 50:\n",
    "                rsi_position_open = False\n",
    "                rsi_signals.append(0)  # Neutral\n",
    "            elif not rsi_position_open and rsi >= 50:\n",
    "                rsi_position_open = True\n",
    "                rsi_signals.append(1)  # Long\n",
    "            else:\n",
    "                rsi_signals.append(rsi_signals[-1] if rsi_signals else 0)\n",
    "        elif strategy_type == 'reversion':\n",
    "            if rsi_position_open and rsi >= 50:\n",
    "                rsi_position_open = False\n",
    "                rsi_signals.append(0)  # Neutral\n",
    "            elif not rsi_position_open and rsi < 50:\n",
    "                rsi_position_open = True\n",
    "                rsi_signals.append(1)  # Long\n",
    "            else:\n",
    "                rsi_signals.append(rsi_signals[-1] if rsi_signals else 0)\n",
    "\n",
    "        rsi_positions.append(rsi_position_open)\n",
    "\n",
    "    candles[rsi_signal_column] = rsi_signals\n",
    "    candles[rsi_position_open_col] = rsi_positions\n",
    "\n",
    "    return candles\n",
    "\n",
    "def update_position_open_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Update the 'position_open' columns for MA and RSI strategies for a specific strategy type (trend or reversion).\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing the signals and position columns.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI signal.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion'\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with 'position_open' columns for the chosen strategy type.\n",
    "    \"\"\"\n",
    "    # Append strategy type to column names\n",
    "    ma_signal_column = f'signal_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_signal_column = f'signal_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_position_open = f'position_open_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_position_open = f'position_open_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    \n",
    "    # Update position open columns based on the signals\n",
    "    candles[ma_position_open] = candles[ma_signal_column] == 1\n",
    "    candles[rsi_position_open] = candles[rsi_signal_column] == 1\n",
    "    \n",
    "    return candles\n",
    "\n",
    "def determine_entry_prices_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', \n",
    "                             ticker_to_tick_size=None, ticker=None, strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Determine entry prices for MA and RSI strategies based on signals.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - ticker_to_tick_size (dict): Mapping of tickers to their tick sizes.\n",
    "    - ticker (str): The ticker for which the tick size applies.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion', affecting the signal logic.\n",
    "    - order_type (str): 'market' or 'limit', defining how entry prices are set.\n",
    "\n",
    "    Returns:\n",
    "    - candles (pd.DataFrame): The DataFrame with updated entry price columns.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names including the strategy type\n",
    "    ma_signal_column = f'signal_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_signal_column = f'signal_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_entry_price = f'entry_price_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_entry_price = f'entry_price_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Initialize entry price columns\n",
    "    candles[ma_entry_price] = None\n",
    "    candles[rsi_entry_price] = None\n",
    "\n",
    "    # Get tick size\n",
    "    tick_size = ticker_to_tick_size.get(ticker, 0) if ticker_to_tick_size else 0\n",
    "\n",
    "    # Determine tick size adjustment based on order type\n",
    "    add_tick_size = order_type == 'market'\n",
    "\n",
    "    # Moving Average Strategy\n",
    "    ma_signals = candles[ma_signal_column]\n",
    "    ma_close_prices = candles['close']\n",
    "    ma_entry_mask = (ma_signals == 1) & (ma_signals.shift(1) != 1)\n",
    "    candles.loc[ma_entry_mask, ma_entry_price] = ma_close_prices[ma_entry_mask] + (tick_size if add_tick_size else 0)\n",
    "\n",
    "    # RSI Strategy\n",
    "    rsi_signals = candles[rsi_signal_column]\n",
    "    rsi_entry_mask = (rsi_signals == 1) & (rsi_signals.shift(1) != 1)\n",
    "    candles.loc[rsi_entry_mask, rsi_entry_price] = ma_close_prices[rsi_entry_mask] + (tick_size if add_tick_size else 0)\n",
    "\n",
    "    return candles\n",
    "\n",
    "def determine_exit_prices_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', \n",
    "                            ticker_to_tick_size=None, ticker=None, strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Determine exit prices for MA and RSI strategies based on signals.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - ticker_to_tick_size (dict): Mapping of tickers to their tick sizes.\n",
    "    - ticker (str): The ticker for which the tick size applies.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion', affecting the signal logic.\n",
    "    - order_type (str): 'market' or 'limit', defining how exit prices are set.\n",
    "\n",
    "    Returns:\n",
    "    - candles (pd.DataFrame): The DataFrame with updated exit price columns.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names including the strategy type\n",
    "    ma_signal_column = f'signal_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_signal_column = f'signal_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_exit_price = f'exit_price_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_exit_price = f'exit_price_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Initialize exit price columns\n",
    "    candles[ma_exit_price] = None\n",
    "    candles[rsi_exit_price] = None\n",
    "\n",
    "    # Get tick size\n",
    "    tick_size = ticker_to_tick_size.get(ticker, 0) if ticker_to_tick_size else 0\n",
    "\n",
    "    # Determine tick size adjustment based on order type\n",
    "    subtract_tick_size = order_type == 'market'\n",
    "\n",
    "    # Moving Average Strategy\n",
    "    ma_signals = candles[ma_signal_column]\n",
    "    ma_close_prices = candles['close']\n",
    "    ma_exit_mask = (ma_signals == 0) & (ma_signals.shift(1) == 1)\n",
    "    candles.loc[ma_exit_mask, ma_exit_price] = ma_close_prices[ma_exit_mask] - (tick_size if subtract_tick_size else 0)\n",
    "\n",
    "    # RSI Strategy\n",
    "    rsi_signals = candles[rsi_signal_column]\n",
    "    rsi_exit_mask = (rsi_signals == 0) & (rsi_signals.shift(1) == 1)\n",
    "    candles.loc[rsi_exit_mask, rsi_exit_price] = ma_close_prices[rsi_exit_mask] - (tick_size if subtract_tick_size else 0)\n",
    "\n",
    "    return candles\n",
    "\n",
    "def calculate_stop_losses_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Dynamically calculate stop loss levels for MA and RSI strategies and ensure they persist while positions are open.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion', affecting column naming.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with dynamically named stop loss columns.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names including the strategy type\n",
    "    ma_entry_price = f'entry_price_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_exit_price = f'exit_price_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_entry_price = f'entry_price_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_exit_price = f'exit_price_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    stop_loss_ma = f'stop_loss_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    stop_loss_rsi = f'stop_loss_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Initialize stop loss columns\n",
    "    candles[stop_loss_ma] = None\n",
    "    candles[stop_loss_rsi] = None\n",
    "\n",
    "    # Moving Average Stop Loss\n",
    "    ma_entry_mask = candles[ma_entry_price].notnull()\n",
    "    ma_exit_mask = candles[ma_exit_price].notnull()\n",
    "    \n",
    "    # Set stop loss where positions open\n",
    "    candles.loc[ma_entry_mask, stop_loss_ma] = candles[ma_entry_price] - candles['candle_span_max']\n",
    "\n",
    "    # Reset stop loss and close position where positions close\n",
    "    candles.loc[ma_exit_mask, stop_loss_ma] = None\n",
    "\n",
    "    # RSI Stop Loss\n",
    "    rsi_entry_mask = candles[rsi_entry_price].notnull()\n",
    "    rsi_exit_mask = candles[rsi_exit_price].notnull()\n",
    "    \n",
    "    # Set stop loss where positions open\n",
    "    candles.loc[rsi_entry_mask, stop_loss_rsi] = candles[rsi_entry_price] - candles['candle_span_max']\n",
    "\n",
    "    # Reset stop loss and close position where positions close\n",
    "    candles.loc[rsi_exit_mask, stop_loss_rsi] = None\n",
    "\n",
    "    # Forward-fill stop loss for both strategies\n",
    "    candles[stop_loss_ma] = candles[stop_loss_ma].ffill()\n",
    "    candles[stop_loss_rsi] = candles[stop_loss_rsi].ffill()\n",
    "\n",
    "    return candles\n",
    "\n",
    "def track_stop_loss_hits_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', ticker_to_tick_size=None, ticker=None, strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Track whether stop losses have been hit for MA and RSI strategies and update dynamically named columns.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - ticker_to_tick_size (dict): Mapping of tickers to their tick sizes.\n",
    "    - ticker (str): The ticker for which the tick size applies.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion', affecting column naming.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with dynamically named stop loss hit flags.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names including strategy type\n",
    "    stop_loss_ma = f'stop_loss_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    stop_loss_rsi = f'stop_loss_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_stop_loss_hit = f'stop_loss_hit_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_stop_loss_hit = f'stop_loss_hit_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_position_open = f'position_open_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_position_open = f'position_open_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Initialize stop loss hit columns\n",
    "    candles[ma_stop_loss_hit] = False\n",
    "    candles[rsi_stop_loss_hit] = False\n",
    "\n",
    "    # Get tick size (ensure it's non-zero)\n",
    "    tick_size = ticker_to_tick_size.get(ticker, 0) if ticker_to_tick_size else 0\n",
    "\n",
    "    # Ensure stop loss values are numerical (convert None to NaN)\n",
    "    candles[stop_loss_ma] = candles[stop_loss_ma].fillna(float('inf'))\n",
    "    candles[stop_loss_rsi] = candles[stop_loss_rsi].fillna(float('inf'))\n",
    "\n",
    "    # Moving Average Stop Loss Hit Logic\n",
    "    ma_hit_condition = (\n",
    "        (candles[stop_loss_ma].notnull()) & \n",
    "        (candles['close'] <= (candles[stop_loss_ma])) & \n",
    "        candles[ma_position_open]\n",
    "    )\n",
    "    candles.loc[ma_hit_condition, ma_stop_loss_hit] = True\n",
    "\n",
    "    # RSI Stop Loss Hit Logic\n",
    "    rsi_hit_condition = (\n",
    "        (candles[stop_loss_rsi].notnull()) & \n",
    "        (candles['close'] <= (candles[stop_loss_rsi])) & \n",
    "        candles[rsi_position_open]\n",
    "    )\n",
    "    candles.loc[rsi_hit_condition, rsi_stop_loss_hit] = True\n",
    "\n",
    "    return candles\n",
    "\n",
    "def adjust_signals_for_stop_loss_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Adjust MA and RSI signals to 0 where stop loss has been hit.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion', affecting column naming.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with adjusted signals.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names including strategy type\n",
    "    ma_signal_column = f'signal_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_signal_column = f'signal_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_stop_loss_hit_column = f'stop_loss_hit_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_stop_loss_hit_column = f'stop_loss_hit_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Adjust MA and RSI signals where stop loss has been hit\n",
    "    candles.loc[candles[ma_stop_loss_hit_column], ma_signal_column] = 0\n",
    "    candles.loc[candles[rsi_stop_loss_hit_column], rsi_signal_column] = 0\n",
    "\n",
    "    return candles\n",
    "\n",
    "def update_stop_loss_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\"\n",
    "    Dynamically set stop loss columns to NaN where corresponding signal columns are 0.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - strategy_type (str): Either 'trend' or 'reversion', affecting column naming.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated DataFrame with dynamically named stop loss columns modified.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names including strategy type\n",
    "    ma_signal_column = f'signal_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_signal_column = f'signal_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    stop_loss_ma = f'stop_loss_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    stop_loss_rsi = f'stop_loss_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Update stop loss columns to NaN where signals are 0\n",
    "    candles.loc[candles[ma_signal_column] == 0, stop_loss_ma] = float('nan')\n",
    "    candles.loc[candles[rsi_signal_column] == 0, stop_loss_rsi] = float('nan')\n",
    "\n",
    "    return candles\n",
    "\n",
    "def calculate_profit_loss_1(candles, ma_name1='wma_5', ma_name2='sma_5', rsi_column='rsi_5', contract_multiplier=1, trade_commission=1.5, strategy_type='trend', order_type='market', directional_bias='long'):\n",
    "    \"\"\" \n",
    "    Dynamically calculate profit and loss based on entry and exit price columns, including cumulative commission costs.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (pd.DataFrame): The DataFrame containing candle data with entry and exit price columns.\n",
    "    - contract_multiplier (float): The multiplier for PnL calculation (e.g., contract size).\n",
    "    - trade_commission (float): The commission cost per trade.\n",
    "    - ma_name1 (str): Column name for the first moving average.\n",
    "    - ma_name2 (str): Column name for the second moving average.\n",
    "    - rsi_column (str): Column name for the RSI indicator.\n",
    "    - strategy_type (str): The type of strategy ('trend' or 'reversion').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with dynamically named profit/loss and commission cost columns.\n",
    "    \"\"\"\n",
    "    # Dynamically generate column names with strategy type\n",
    "    ma_entry_price = f'entry_price_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_exit_price = f'exit_price_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_entry_price = f'entry_price_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_exit_price = f'exit_price_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    pnl_ma_col = f'pnl_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    pnl_rsi_col = f'pnl_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    cum_pnl_ma_col = f'cum_{pnl_ma_col}'\n",
    "    cum_pnl_rsi_col = f'cum_{pnl_rsi_col}'\n",
    "    cum_pnl_all_col = f'cum_pnl_all_{ma_name1}_{ma_name2}_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    ma_commission_col = f'commission_cost_{ma_name1}_{ma_name2}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "    rsi_commission_col = f'commission_cost_{rsi_column}_{strategy_type}_{order_type}_{directional_bias}'\n",
    "\n",
    "    # Initialize PnL and commission columns\n",
    "    candles[pnl_ma_col] = 0.0\n",
    "    candles[pnl_rsi_col] = 0.0\n",
    "    candles[ma_commission_col] = 0.0\n",
    "    candles[rsi_commission_col] = 0.0\n",
    "\n",
    "    # Moving Average Strategy PnL and Commission Calculation\n",
    "    ma_entry_indices = candles.index[candles[ma_entry_price].notnull()]\n",
    "    ma_exit_indices = candles.index[candles[ma_exit_price].notnull()]\n",
    "\n",
    "    # Pair up entry and exit prices\n",
    "    valid_pairs_ma = min(len(ma_entry_indices), len(ma_exit_indices))\n",
    "    ma_entry_prices = candles.loc[ma_entry_indices[:valid_pairs_ma], ma_entry_price].values\n",
    "    ma_exit_prices = candles.loc[ma_exit_indices[:valid_pairs_ma], ma_exit_price].values\n",
    "\n",
    "    # Calculate commission costs for MA strategy\n",
    "    candles[ma_commission_col] = candles[ma_entry_price].notna().astype(int) * trade_commission + \\\n",
    "                                 candles[ma_exit_price].notna().astype(int) * trade_commission\n",
    "    candles[ma_commission_col] = candles[ma_commission_col].cumsum()  # Accumulate commission costs\n",
    "\n",
    "    # Calculate PnL for MA strategy\n",
    "    ma_pnl = (ma_exit_prices - ma_entry_prices) * contract_multiplier\n",
    "    candles.loc[ma_exit_indices[:valid_pairs_ma], pnl_ma_col] = ma_pnl\n",
    "\n",
    "    # RSI Strategy PnL and Commission Calculation\n",
    "    rsi_entry_indices = candles.index[candles[rsi_entry_price].notnull()]\n",
    "    rsi_exit_indices = candles.index[candles[rsi_exit_price].notnull()]\n",
    "\n",
    "    # Pair up entry and exit prices\n",
    "    valid_pairs_rsi = min(len(rsi_entry_indices), len(rsi_exit_indices))\n",
    "    rsi_entry_prices = candles.loc[rsi_entry_indices[:valid_pairs_rsi], rsi_entry_price].values\n",
    "    rsi_exit_prices = candles.loc[rsi_exit_indices[:valid_pairs_rsi], rsi_exit_price].values\n",
    "\n",
    "    # Calculate commission costs for RSI strategy\n",
    "    candles[rsi_commission_col] = candles[rsi_entry_price].notna().astype(int) * trade_commission + \\\n",
    "                                  candles[rsi_exit_price].notna().astype(int) * trade_commission\n",
    "    candles[rsi_commission_col] = candles[rsi_commission_col].cumsum()  # Accumulate commission costs\n",
    "\n",
    "    # Calculate PnL for RSI strategy\n",
    "    rsi_pnl = (rsi_exit_prices - rsi_entry_prices) * contract_multiplier\n",
    "    candles.loc[rsi_exit_indices[:valid_pairs_rsi], pnl_rsi_col] = rsi_pnl\n",
    "\n",
    "    # Calculate cumulative PnL for both strategies\n",
    "    candles[cum_pnl_ma_col] = candles[pnl_ma_col].cumsum()\n",
    "    candles[cum_pnl_rsi_col] = candles[pnl_rsi_col].cumsum()\n",
    "\n",
    "    # Calculate combined cumulative PnL\n",
    "    candles[cum_pnl_all_col] = candles[cum_pnl_ma_col] + candles[cum_pnl_rsi_col]\n",
    "\n",
    "    return candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3add6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a variable to track if a position is open (market neutral) for function `trade_logic`\n",
    "# position_open = False  # False means market neutral, True means a trade is active\n",
    "# entry_price = None  # Store the entry price when a trade is opened\n",
    "\n",
    "# # Initialize a variable to track if a position is open (market neutral) for function `trade_logic`\n",
    "# sim_position_open = False  # False means market neutral, True means a trade is active\n",
    "# sim_entry_price = None  # Store the entry price when a trade is opened\n",
    "\n",
    "# def trade_logic(candles, buy_order=None, sell_order=None):\n",
    "#     \"\"\"\n",
    "#     Function to decide whether to go long or close positions based on the signal column.\n",
    "\n",
    "#     Parameters:\n",
    "#     - candles (pd.DataFrame): The DataFrame containing minute candle data.\n",
    "#     - buy_order (dict): The buy order configuration (market order).\n",
    "#     - sell_order (dict): The sell order configuration (market order).\n",
    "#     \"\"\"\n",
    "\n",
    "#     global position_open, entry_price  # Ensure access to global variables\n",
    "\n",
    "#     current_hour = datetime.now(pytz.timezone('US/Eastern')).hour\n",
    "#     current_minute = datetime.now(pytz.timezone('US/Eastern')).minute\n",
    "#     current_second = datetime.now(pytz.timezone('US/Eastern')).second\n",
    "\n",
    "#     # Check if it's the start of a new minute (second == 00)\n",
    "#     if current_second == 0 or 1:\n",
    "#         # Ensure there is enough data in candles (at least 2 rows to check the previous signal)\n",
    "#         if len(candles) < 2:\n",
    "#             print(\"Not enough data to make a trade decision.\")\n",
    "#             return\n",
    "\n",
    "#         # Get the signal from the row before the one currently forming\n",
    "#         previous_signal = candles.iloc[-2]['signal']\n",
    "\n",
    "#         if previous_signal == 1:\n",
    "#             # If signal is 1 and no position is open, go long (buy)\n",
    "#             if not position_open:\n",
    "#                 # Place buy order\n",
    "#                 resp = client.order_place(account_hash, buy_order)\n",
    "#                 print(f\"Buy order placed. Response: {resp}\")\n",
    "                \n",
    "#                 # Mark position as open and record entry price\n",
    "#                 position_open = True\n",
    "#                 entry_price = candles.iloc[-2]['close']\n",
    "#                 print(f\"Bought at {entry_price}\")\n",
    "#             else:\n",
    "#                 print(\"Position already open, no action taken.\")\n",
    "\n",
    "#         elif previous_signal == 0 or previous_signal == -1:\n",
    "#             # If signal is 0 or -1 and a position is open, close the position (sell)\n",
    "#             if position_open:\n",
    "#                 # Place sell order\n",
    "#                 resp = client.order_place(account_hash, sell_order)\n",
    "#                 print(f\"Sell order placed. Response: {resp}\")\n",
    "                \n",
    "#                 # Close position\n",
    "#                 position_open = False\n",
    "#                 print(f\"Sold at {candles.iloc[-2]['close']}\")\n",
    "#             else:\n",
    "#                 print(\"No position open, no action taken.\")\n",
    "\n",
    "# def trade_simulator(candles):\n",
    "#     \"\"\"\n",
    "#     Simulated function to decide whether to go long or close positions based on the signal column.\n",
    "\n",
    "#     Parameters:\n",
    "#     - candles (pd.DataFrame): The DataFrame containing minute candle data.\n",
    "\n",
    "#     The function updates the 'sim_signal', 'sim_entry', and 'sim_exit' columns in the DataFrame.\n",
    "#     \"\"\"\n",
    "\n",
    "#     global sim_position_open, sim_entry_price  # Ensure access to global variables\n",
    "\n",
    "#     # Initialize the new columns if they don't exist\n",
    "#     if 'sim_signal' not in candles.columns:\n",
    "#         candles['sim_signal'] = None\n",
    "#     if 'sim_entry' not in candles.columns:\n",
    "#         candles['sim_entry'] = None\n",
    "#     if 'sim_exit' not in candles.columns:\n",
    "#         candles['sim_exit'] = None\n",
    "\n",
    "#     current_hour = datetime.now(pytz.timezone('US/Eastern')).hour\n",
    "#     current_minute = datetime.now(pytz.timezone('US/Eastern')).minute\n",
    "#     current_second = datetime.now(pytz.timezone('US/Eastern')).second\n",
    "\n",
    "#     # Check if it's the start of a new minute (second == 00)\n",
    "#     if current_second == 0 or 1:\n",
    "#         # Ensure there is enough data in candles (at least 2 rows to check the previous signal)\n",
    "#         if len(candles) < 2:\n",
    "#             print(\"Not enough data to make a trade decision.\")\n",
    "#             return\n",
    "\n",
    "#         # Get the signal from the row before the one currently forming\n",
    "#         sim_previous_signal = candles.iloc[-2]['signal']\n",
    "\n",
    "#         if sim_previous_signal == 1:\n",
    "#             # If signal is 1 and no position is open, simulate going long (buy)\n",
    "#             if not sim_position_open:\n",
    "#                 # Simulate buy entry\n",
    "#                 sim_entry_price = candles.iloc[-2]['close']\n",
    "#                 sim_position_open = True\n",
    "                \n",
    "#                 # Record simulated signal and entry price in the DataFrame\n",
    "#                 candles.at[candles.index[-2], 'sim_signal'] = 1\n",
    "#                 candles.at[candles.index[-2], 'sim_entry'] = sim_entry_price\n",
    "\n",
    "#                 print(f\"Simulated buy at {sim_entry_price}\")\n",
    "\n",
    "#             else:\n",
    "#                 print(\"Position already open, no action taken.\")\n",
    "\n",
    "#         elif sim_previous_signal == 0 or sim_previous_signal == -1:\n",
    "#             # If signal is 0 or -1 and a position is open, simulate closing the position (sell)\n",
    "#             if sim_position_open:\n",
    "#                 # Simulate sell exit\n",
    "#                 sim_exit_price = candles.iloc[-2]['close']\n",
    "#                 sim_position_open = False\n",
    "\n",
    "#                 # Record simulated signal and exit price in the DataFrame\n",
    "#                 candles.at[candles.index[-2], 'sim_signal'] = -1\n",
    "#                 candles.at[candles.index[-2], 'sim_exit'] = sim_exit_price\n",
    "\n",
    "#                 print(f\"Simulated sell at {sim_exit_price}\")\n",
    "#             else:\n",
    "#                 print(\"No position open, no action taken.\")\n",
    "\n",
    "# def trade_simulator(candles):\n",
    "#     \"\"\"\n",
    "#     Simulated function to decide whether to go long or close positions based on the signal column.\n",
    "\n",
    "#     Parameters:\n",
    "#     - candles (pd.DataFrame): The DataFrame containing minute candle data.\n",
    "\n",
    "#     The function updates the 'sim_signal' and 'sim_price' columns in the DataFrame.\n",
    "#     \"\"\"\n",
    "\n",
    "#     global sim_position_open, sim_entry_price  # Ensure access to global variables\n",
    "\n",
    "#     current_time = datetime.now(pytz.timezone('US/Eastern'))\n",
    "#     current_hour = datetime.now(pytz.timezone('US/Eastern')).hour    \n",
    "#     current_minute = datetime.now(pytz.timezone('US/Eastern')).minute\n",
    "#     current_second = datetime.now(pytz.timezone('US/Eastern')).second\n",
    "\n",
    "#     # Initialize the new columns if they don't exist\n",
    "#     if 'sim_signal' not in candles.columns:\n",
    "#         candles['sim_signal'] = None\n",
    "#     if 'sim_price' not in candles.columns:\n",
    "#         candles['sim_price'] = None\n",
    "\n",
    "#     # Check if it's the start of a new minute (second == 00)\n",
    "#     if current_time.second == 0:\n",
    "#         # Ensure there is enough data in candles (at least 2 rows to check the previous signal)\n",
    "#         if len(candles) < 2:\n",
    "#             print(\"Not enough data to make a trade decision.\")\n",
    "#             return\n",
    "\n",
    "#         # Get the signal from the row before the one currently forming\n",
    "#         sim_previous_signal = candles.iloc[-2]['signal']\n",
    "\n",
    "#         if sim_previous_signal == 1:\n",
    "#             # If signal is 1 and no position is open, simulate going long (buy)\n",
    "#             if not sim_position_open:\n",
    "#                 # Simulate buy entry\n",
    "#                 sim_entry_price = candles.iloc[-2]['close']\n",
    "#                 sim_position_open = True\n",
    "                \n",
    "#                 # Record simulated signal and entry price in the DataFrame\n",
    "#                 candles.at[candles.index[-2], 'sim_signal'] = 1\n",
    "#                 candles.at[candles.index[-2], 'sim_price'] = sim_entry_price\n",
    "\n",
    "#                 print(f\"Simulated buy at {sim_entry_price}\")\n",
    "\n",
    "#             else:\n",
    "#                 print(\"Position already open, no action taken.\")\n",
    "\n",
    "#         elif sim_previous_signal == 0 or sim_previous_signal == -1:\n",
    "#             # If signal is 0 or -1 and a position is open, simulate closing the position (sell)\n",
    "#             if sim_position_open:\n",
    "#                 # Simulate sell exit\n",
    "#                 sim_exit_price = candles.iloc[-2]['close']\n",
    "#                 sim_position_open = False\n",
    "\n",
    "#                 # Record simulated signal and exit price in the DataFrame\n",
    "#                 candles.at[candles.index[-2], 'sim_signal'] = -1\n",
    "#                 candles.at[candles.index[-2], 'sim_price'] = sim_exit_price\n",
    "\n",
    "#                 print(f\"Simulated sell at {sim_exit_price}\")\n",
    "#             else:\n",
    "#                 print(\"No position open, no action taken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635917d",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\"><b>The Data Handler<b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_accounts = client.account_linked().json()\n",
    "linked_accounts\n",
    "\n",
    "account_hash = linked_accounts[0].get('hashValue')\n",
    "print(account_hash)\n",
    "\n",
    "# equity_ticker = 'MARA'\n",
    "futures_ticker = '/NQ'\n",
    "\n",
    "buy_order = {\"orderType\": \"MARKET\",\n",
    "        \"session\": \"NORMAL\",\n",
    "        \"duration\": \"DAY\",\n",
    "        \"orderStrategyType\": \"SINGLE\",\n",
    "        \"orderLegCollection\": [\n",
    "            {\n",
    "                \"instruction\": \"BUY\",\n",
    "                \"quantity\": 1,\n",
    "                \"instrument\": {\n",
    "                    \"symbol\": futures_ticker,\n",
    "                    \"assetType\": \"EQUITY\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }  \n",
    "\n",
    "sell_order = {\"orderType\": \"MARKET\",\n",
    "        \"session\": \"NORMAL\",\n",
    "        \"duration\": \"DAY\",\n",
    "        \"orderStrategyType\": \"SINGLE\",\n",
    "        \"orderLegCollection\": [\n",
    "            {\n",
    "                \"instruction\": \"SELL\",\n",
    "                \"quantity\": 1,\n",
    "                \"instrument\": {\n",
    "                    \"symbol\": futures_ticker,\n",
    "                    \"assetType\": \"EQUITY\"\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = client.stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc67ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = \"/ES,/NQ,/CL,/GC\"\n",
    "# tickers = \"MARA,PLUG,SOFI,SWN,RKLB\"\n",
    "\n",
    "ticker_to_point_value = {\n",
    "    \"/ES\": 50,       # E-Mini S&P 500\n",
    "    \"/NQ\": 20,       # E-Mini NASDAQ 100\n",
    "    \"/CL\": 1000,     # Crude Oil\n",
    "    \"/GC\": 100,      # Gold\n",
    "}\n",
    "\n",
    "ticker_to_tick_size = {\n",
    "    \"/ES\": 0.25,        # E-Mini S&P 500\n",
    "    \"/NQ\": 0.25,        # E-Mini NASDAQ 100\n",
    "    \"/CL\": 0.01,        # Crude Oil\n",
    "    \"/GC\": 0.1,         # Gold\n",
    "}\n",
    "\n",
    "ma_periods = [1, 3, 5]\n",
    "sma_periods = ma_periods\n",
    "wma_periods = ma_periods\n",
    "rsi_periods = ma_periods\n",
    "\n",
    "ma_combinations = [\n",
    "    (f'wma_{wma}', f'sma_{sma}', f'rsi_{wma}')\n",
    "    for wma in wma_periods\n",
    "    for sma in sma_periods\n",
    "    if wma <= sma\n",
    "]\n",
    "\n",
    "compression_factors = range(1, 6, 2)\n",
    "\n",
    "def handle_data(message):\n",
    "    global minute_candles\n",
    "\n",
    "    current_time_USE = datetime.now(pytz.timezone('US/Eastern')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    current_hour = datetime.now(pytz.timezone('US/Eastern')).hour\n",
    "    current_minute = datetime.now(pytz.timezone('US/Eastern')).minute\n",
    "    current_second = datetime.now(pytz.timezone('US/Eastern')).second\n",
    "\n",
    "    # Stop the streamer at 16:59:55\n",
    "    if current_hour == 16 and current_minute == 59 and current_second >= 55:\n",
    "        print(f\"{current_time_USE.strftime('%Y-%m-%d %H:%M:%S')} - Stopping the streamer.\")\n",
    "        streamer.stop(clear_subscriptions=True)\n",
    "        return  # Exit the function immediately after stopping the streamer\n",
    "\n",
    "    # Try parsing the incoming message\n",
    "    try: # Indent the code and uncomment the try-except block to revert\n",
    "        data = json.loads(message)\n",
    "\n",
    "        # Call the function to process the data and update todays_price_action\n",
    "        process_message_data(data)\n",
    "\n",
    "        # **Update the minute candles in real-time**\n",
    "        update_minute_candles(ticker_tables, time_frame='min')\n",
    "\n",
    "        # Compress each ticker in minute_candles in real-time\n",
    "        for ticker, df in minute_candles.items():\n",
    "            for compression_factor in compression_factors:\n",
    "                dynamic_name = f\"{compression_factor}_minute_compression\"\n",
    "                compressed_sessions[ticker][dynamic_name] = compress_candles(df, compression_factor)\n",
    "\n",
    "\n",
    "        # Iterate through all the tickers in minute_candles\n",
    "        for ticker, compressions in compressed_sessions.items():\n",
    "            for compression_name, df in compressions.items():\n",
    "                    # Calculate moving averages and indicators for each DataFrame\n",
    "                    compressed_sessions[ticker][compression_name] = calculate_indicators_1(\n",
    "                        df, \n",
    "                        price_col='close', \n",
    "                        acc_vol_col='accumulative_volume', \n",
    "                        sma_periods=sma_periods,\n",
    "                        wma_periods=wma_periods,\n",
    "                        rsi_periods=rsi_periods,\n",
    "                        candle_window=10\n",
    "                    )\n",
    "        \n",
    "        # ANY TRADE STRATEGY LOGIC IS TO GO BETWEEN THE LINES OF ASTERISKS\n",
    "        # *********************************************************************************************************************************************************************************\n",
    "        strategy_types = ['trend', 'reversion']\n",
    "        order_types = ['market', 'limit']\n",
    "        directional_biases = ['long', 'short']\n",
    "        directional_bias = 'long'\n",
    "\n",
    "        # Iterate through all tickers in compressed_sessions\n",
    "        for ticker, sessions in compressed_sessions.items():\n",
    "            print(f\"Processing ticker: {ticker}\")\n",
    "\n",
    "            # Iterate through all sessions of the current ticker\n",
    "            for time_slice, compressions in sessions.items():\n",
    "                print(f\"  {ticker} Processing session: {time_slice}, Total Compressions: {len(compressions)}\")\n",
    "\n",
    "                # Iterate through all compression levels of the current session\n",
    "                for compression_name, df in compressions.items():\n",
    "                    print(f\"    {ticker} Processing compression: {compression_name} in session {time_slice}\")\n",
    "\n",
    "                    # Iterate through all the ma_combinations\n",
    "                    for sig_ma, con_ma, rsi_col in ma_combinations:\n",
    "\n",
    "                        for strategy_type in strategy_types:\n",
    "                            print(f\"      {ticker} {time_slice} {compression_name} Applying {strategy_type} strategy for {sig_ma} and {con_ma}\")\n",
    "                            \n",
    "                            for order_type in order_types:\n",
    "                                print(f\"        {ticker} Applying {order_type} order_type\")\n",
    "\n",
    "                                # for directional_bias in directional_biases:\n",
    "                                #     print(f\"          Applying {directional_bias} directional bias\")\n",
    "\n",
    "                                # Generate trading signals for the current strategy\n",
    "                                compressions[compression_name] = generate_trading_signals_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Update position_open columns to be 1:1 verbal boolean with the signal\n",
    "                                compressions[compression_name] = update_position_open_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Determine entry prices for each ticker\n",
    "                                compressions[compression_name] = determine_entry_prices_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    ticker_to_tick_size=ticker_to_tick_size,\n",
    "                                    ticker=ticker,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Determine exit prices for each ticker\n",
    "                                compressions[compression_name] = determine_exit_prices_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    ticker_to_tick_size=ticker_to_tick_size,\n",
    "                                    ticker=ticker,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Stop loss calculation\n",
    "                                compressions[compression_name] = calculate_stop_losses_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Track stop loss hits\n",
    "                                compressions[compression_name] = track_stop_loss_hits_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    ticker_to_tick_size=ticker_to_tick_size,\n",
    "                                    ticker=ticker,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Adjust signals from stop loss hits\n",
    "                                compressions[compression_name] = adjust_signals_for_stop_loss_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Re-update position_open column after stop loss hits\n",
    "                                compressions[compression_name] = update_position_open_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Re-determine entry prices after stop loss hits\n",
    "                                compressions[compression_name] = determine_entry_prices_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    ticker_to_tick_size=ticker_to_tick_size,\n",
    "                                    ticker=ticker,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Re-determine exit prices after stop loss hits\n",
    "                                compressions[compression_name] = determine_exit_prices_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    ticker_to_tick_size=ticker_to_tick_size,\n",
    "                                    ticker=ticker,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                )\n",
    "\n",
    "                                # Update stop loss levels after stop loss hits\n",
    "                                compressions[compression_name] = update_stop_loss_1(\n",
    "                                    df,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias\n",
    "                                    \n",
    "                                )\n",
    "\n",
    "                                # Calculate profit/loss for each ticker's DataFrame\n",
    "                                compressions[compression_name] = calculate_profit_loss_1(\n",
    "                                    df,\n",
    "                                    contract_multiplier=1,\n",
    "                                    ma_name1=sig_ma,\n",
    "                                    ma_name2=con_ma,\n",
    "                                    rsi_column=rsi_col,\n",
    "                                    strategy_type=strategy_type,\n",
    "                                    order_type=order_type,\n",
    "                                    directional_bias=directional_bias   \n",
    "                                )\n",
    "        # *********************************************************************************************************************************************************************************        \n",
    "        # ANY TRADE STRATEGY LOGIC IS TO GO BETWEEN THE LINES OF ASTERISKS\n",
    "\n",
    "        if current_second == 59 or 00 or 1 or 2:\n",
    "            # Call the trade_logic function to execute trades based on the signal\n",
    "            trade_logic(minute_candles, buy_order=buy_order, sell_order=sell_order)\n",
    "\n",
    "        if current_second == 59 or 00 or 1 or 2:\n",
    "            # Call the trade_simulator function to simulate trades based on the signal\n",
    "            trade_simulator(minute_candles)\n",
    "\n",
    "            print(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{current_time_USE}: Error processing message: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5888ad",
   "metadata": {},
   "source": [
    "Suppress all warnings to avoid too much printing under the streamer cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe668de",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ecfa0",
   "metadata": {},
   "source": [
    "Start the streamer and send the level one futures subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76756369",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer.start(handle_data)\n",
    "streamer.send(streamer.level_one_futures(tickers, \"0,1,2,3,4,5,8,9,12,13,14,18,19,20,23,25,26,35,37,38\")) # For futures\n",
    "# streamer.send(streamer.level_one_equities(tickers, \"0,1,2,3,4,5,8,9,10,11,12,17,18,19,20,21,42\")) # For equities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4450a",
   "metadata": {},
   "source": [
    "Stop the streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer.stop(clear_subscriptions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dceee1",
   "metadata": {},
   "source": [
    "Append new data to the csv storage files that contain the raw, manually collected OHLC data from Schwab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a306b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended to: raw_futures_data/ES.csv\n",
      "Appended to: raw_futures_data/NQ.csv\n",
      "Appended to: raw_futures_data/CL.csv\n",
      "Appended to: raw_futures_data/GC.csv\n"
     ]
    }
   ],
   "source": [
    "def save_dfs_to_csv(candles, save_path=\"raw_futures_data/\", columns_to_save=None):\n",
    "    \"\"\" After specifying column data types\n",
    "    Save each DataFrame in the dictionary to a separate CSV file, appending to the CSV\n",
    "    if the file already exists, saving only specified columns with enforced data types.\n",
    "\n",
    "    Parameters:\n",
    "    - candles (dict): A dictionary where keys are names and values are DataFrames.\n",
    "    - save_path (str): The directory where the CSV files will be saved. Default is 'dataframes/'.\n",
    "    - columns_to_save (list): A list of columns to save from each DataFrame. Default is None (save all columns).\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Define column data types\n",
    "    dtype_conversion = {\n",
    "        'open': 'float64',\n",
    "        'high': 'float64',\n",
    "        'low': 'float64',\n",
    "        'close': 'float64',\n",
    "        'accumulative_volume': 'float64'\n",
    "    }\n",
    "\n",
    "    # Save each DataFrame\n",
    "    for key, df in candles.items():\n",
    "        file_name = os.path.join(save_path, f\"{key.replace(\"/\", \"\")}.csv\")\n",
    "\n",
    "        # Filter the DataFrame to only the specified columns, if provided\n",
    "        if columns_to_save:\n",
    "            df_to_save = df[columns_to_save].copy()\n",
    "        else:\n",
    "            df_to_save = df.copy()\n",
    "\n",
    "        # Ensure correct data types for numeric columns\n",
    "        for col, dtype in dtype_conversion.items():\n",
    "            if col in df_to_save.columns:\n",
    "                df_to_save[col] = df_to_save[col].astype(dtype, errors='ignore')\n",
    "\n",
    "        # Save the DataFrame\n",
    "        if os.path.exists(file_name):\n",
    "            df_to_save.to_csv(file_name, mode='a', header=False, index=False)\n",
    "            print(f\"Appended to: {file_name}\")\n",
    "        else:\n",
    "            df_to_save.to_csv(file_name, index=False)\n",
    "            print(f\"Saved new file: {file_name}\")\n",
    "\n",
    "columns_to_save = ['datetime', 'ticker', 'open', 'high', 'low', 'close', 'accumulative_volume']\n",
    "save_dfs_to_csv(minute_candles, save_path=\"raw_futures_data/\", columns_to_save=columns_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5794cc",
   "metadata": {},
   "source": [
    "Inspect data from the current session. Check current time to see if the streamer has been cut off. Restart the streamer if it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf277114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/ES':                       datetime ticker       open       high        low  \\\n",
       " 0    2025-05-12 18:12:00-04:00    /ES 5,864.0000 5,864.7500 5,863.7500   \n",
       " 1    2025-05-12 18:13:00-04:00    /ES 5,864.5000 5,864.5000 5,863.0000   \n",
       " 2    2025-05-12 18:14:00-04:00    /ES 5,863.2500 5,863.2500 5,863.0000   \n",
       " 3    2025-05-12 18:15:00-04:00    /ES 5,863.2500 5,863.5000 5,862.5000   \n",
       " 4    2025-05-12 18:16:00-04:00    /ES 5,863.0000 5,864.0000 5,862.0000   \n",
       " ...                        ...    ...        ...        ...        ...   \n",
       " 1290 2025-05-13 15:42:00-04:00    /ES 5,921.7500 5,924.0000 5,921.7500   \n",
       " 1291 2025-05-13 15:43:00-04:00    /ES 5,923.7500 5,924.0000 5,922.2500   \n",
       " 1292 2025-05-13 15:44:00-04:00    /ES 5,922.5000 5,923.0000 5,922.0000   \n",
       " 1293 2025-05-13 15:45:00-04:00    /ES 5,922.2500 5,922.7500 5,920.0000   \n",
       " 1294 2025-05-13 15:46:00-04:00    /ES 5,920.2500 5,921.5000 5,919.7500   \n",
       " \n",
       "           close accumulative_volume  \n",
       " 0    5,864.5000                2454  \n",
       " 1    5,863.2500                2572  \n",
       " 2    5,863.2500                2645  \n",
       " 3    5,863.0000                2780  \n",
       " 4    5,864.0000                2956  \n",
       " ...         ...                 ...  \n",
       " 1290 5,924.0000             1087856  \n",
       " 1291 5,922.7500             1090318  \n",
       " 1292 5,922.5000             1092384  \n",
       " 1293 5,920.5000             1095699  \n",
       " 1294 5,921.0000             1097798  \n",
       " \n",
       " [1295 rows x 7 columns],\n",
       " '/NQ':                       datetime ticker        open        high         low  \\\n",
       " 0    2025-05-12 18:12:00-04:00    /NQ 20,938.5000 20,942.5000 20,938.5000   \n",
       " 1    2025-05-12 18:13:00-04:00    /NQ 20,942.0000 20,942.0000 20,934.7500   \n",
       " 2    2025-05-12 18:14:00-04:00    /NQ 20,936.0000 20,936.0000 20,932.5000   \n",
       " 3    2025-05-12 18:15:00-04:00    /NQ 20,933.5000 20,936.2500 20,932.2500   \n",
       " 4    2025-05-12 18:16:00-04:00    /NQ 20,933.5000 20,939.2500 20,927.7500   \n",
       " ...                        ...    ...         ...         ...         ...   \n",
       " 1290 2025-05-13 15:42:00-04:00    /NQ 21,319.5000 21,330.0000 21,319.5000   \n",
       " 1291 2025-05-13 15:43:00-04:00    /NQ 21,329.2500 21,329.5000 21,321.7500   \n",
       " 1292 2025-05-13 15:44:00-04:00    /NQ 21,322.0000 21,324.0000 21,320.0000   \n",
       " 1293 2025-05-13 15:45:00-04:00    /NQ 21,322.5000 21,323.0000 21,311.7500   \n",
       " 1294 2025-05-13 15:46:00-04:00    /NQ 21,313.5000 21,317.7500 21,309.5000   \n",
       " \n",
       "            close accumulative_volume  \n",
       " 0    20,942.0000                1398  \n",
       " 1    20,936.0000                1446  \n",
       " 2    20,933.5000                1534  \n",
       " 3    20,934.2500                1646  \n",
       " 4    20,939.2500                1831  \n",
       " ...          ...                 ...  \n",
       " 1290 21,330.0000              464744  \n",
       " 1291 21,323.2500              465291  \n",
       " 1292 21,322.5000              465782  \n",
       " 1293 21,315.0000              466716  \n",
       " 1294 21,316.0000              467571  \n",
       " \n",
       " [1295 rows x 7 columns],\n",
       " '/CL':                       datetime ticker    open    high     low   close  \\\n",
       " 0    2025-05-12 18:12:00-04:00    /CL 61.9900 61.9900 61.9900 61.9900   \n",
       " 1    2025-05-12 18:13:00-04:00    /CL 61.9900 62.0200 61.9900 62.0200   \n",
       " 2    2025-05-12 18:14:00-04:00    /CL 62.0200 62.0300 62.0000 62.0300   \n",
       " 3    2025-05-12 18:15:00-04:00    /CL 62.0300 62.0400 62.0300 62.0400   \n",
       " 4    2025-05-12 18:16:00-04:00    /CL 62.0400 62.0500 62.0300 62.0300   \n",
       " ...                        ...    ...     ...     ...     ...     ...   \n",
       " 1290 2025-05-13 15:42:00-04:00    /CL 63.7200 63.7200 63.7100 63.7100   \n",
       " 1291 2025-05-13 15:43:00-04:00    /CL 63.7100 63.7100 63.7000 63.7100   \n",
       " 1292 2025-05-13 15:44:00-04:00    /CL 63.7100 63.7100 63.6900 63.7000   \n",
       " 1293 2025-05-13 15:45:00-04:00    /CL 63.7000 63.7000 63.6900 63.6900   \n",
       " 1294 2025-05-13 15:46:00-04:00    /CL 63.6900 63.7000 63.6900 63.6900   \n",
       " \n",
       "      accumulative_volume  \n",
       " 0                    716  \n",
       " 1                    738  \n",
       " 2                    757  \n",
       " 3                    779  \n",
       " 4                    796  \n",
       " ...                  ...  \n",
       " 1290              213582  \n",
       " 1291              213652  \n",
       " 1292              213723  \n",
       " 1293              213885  \n",
       " 1294              213953  \n",
       " \n",
       " [1295 rows x 7 columns],\n",
       " '/GC':                       datetime ticker       open       high        low  \\\n",
       " 0    2025-05-12 18:12:00-04:00    /GC 3,239.0000 3,239.0000 3,238.3000   \n",
       " 1    2025-05-12 18:13:00-04:00    /GC 3,238.2000 3,240.6000 3,238.2000   \n",
       " 2    2025-05-12 18:14:00-04:00    /GC 3,240.1000 3,240.8000 3,240.1000   \n",
       " 3    2025-05-12 18:15:00-04:00    /GC 3,240.8000 3,241.6000 3,240.8000   \n",
       " 4    2025-05-12 18:16:00-04:00    /GC 3,241.3000 3,241.9000 3,241.3000   \n",
       " ...                        ...    ...        ...        ...        ...   \n",
       " 1290 2025-05-13 15:42:00-04:00    /GC 3,254.0000 3,254.2000 3,253.9000   \n",
       " 1291 2025-05-13 15:43:00-04:00    /GC 3,253.9000 3,254.3000 3,253.6000   \n",
       " 1292 2025-05-13 15:44:00-04:00    /GC 3,253.5000 3,253.9000 3,253.4000   \n",
       " 1293 2025-05-13 15:45:00-04:00    /GC 3,253.8000 3,254.0000 3,253.7000   \n",
       " 1294 2025-05-13 15:46:00-04:00    /GC 3,253.8000 3,253.8000 3,252.6000   \n",
       " \n",
       "           close accumulative_volume  \n",
       " 0    3,238.3000                1003  \n",
       " 1    3,240.0000                1064  \n",
       " 2    3,240.8000                1088  \n",
       " 3    3,241.3000                1130  \n",
       " 4    3,241.4000                1159  \n",
       " ...         ...                 ...  \n",
       " 1290 3,253.9000              197677  \n",
       " 1291 3,253.8000              197724  \n",
       " 1292 3,253.8000              197752  \n",
       " 1293 3,253.9000              197770  \n",
       " 1294 3,252.6000              197872  \n",
       " \n",
       " [1295 rows x 7 columns]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['/ES', '/NQ', '/CL', '/GC']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>key</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>last_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>last_size</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>net_change</th>\n",
       "      <th>future_pct_change</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>tick</th>\n",
       "      <th>tick_amount</th>\n",
       "      <th>future_exp_date</th>\n",
       "      <th>ask_time</th>\n",
       "      <th>bid_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-05-12 18:12:02.003000-04:00</th>\n",
       "      <td>1747087922003</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,937.7500</td>\n",
       "      <td>20,939.7500</td>\n",
       "      <td>20,938.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1344</td>\n",
       "      <td>1</td>\n",
       "      <td>20,963.5000</td>\n",
       "      <td>20,931.7500</td>\n",
       "      <td>20,136.7500</td>\n",
       "      <td>20,954.7500</td>\n",
       "      <td>801.7500</td>\n",
       "      <td>3.9815</td>\n",
       "      <td>259062</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>5</td>\n",
       "      <td>1750392000000</td>\n",
       "      <td>1747087921300</td>\n",
       "      <td>1747087921227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-12 18:12:03.026000-04:00</th>\n",
       "      <td>1747087923026</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,939.5000</td>\n",
       "      <td>20,941.7500</td>\n",
       "      <td>20,940.7500</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>1350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>804.0000</td>\n",
       "      <td>3.9927</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747087922568</td>\n",
       "      <td>1747087922893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-12 18:12:04.029000-04:00</th>\n",
       "      <td>1747087924029</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,939.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20,941.7500</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1351</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805.0000</td>\n",
       "      <td>3.9977</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747087923256</td>\n",
       "      <td>1747087923707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-12 18:12:07.138000-04:00</th>\n",
       "      <td>1747087927138</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20,941.7500</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747087926812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-12 18:12:08.161000-04:00</th>\n",
       "      <td>1747087928161</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,940.7500</td>\n",
       "      <td>20,942.7500</td>\n",
       "      <td>20,942.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805.7500</td>\n",
       "      <td>4.0014</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747087927253</td>\n",
       "      <td>1747087927281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-13 15:46:54.415000-04:00</th>\n",
       "      <td>1747165614415</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,314.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21,314.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>467548</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747165614255</td>\n",
       "      <td>1747165614255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-13 15:46:55.422000-04:00</th>\n",
       "      <td>1747165615422</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,316.0000</td>\n",
       "      <td>21,316.5000</td>\n",
       "      <td>21,316.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>467554</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367.5000</td>\n",
       "      <td>1.7543</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747165615257</td>\n",
       "      <td>1747165615177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-13 15:46:56.431000-04:00</th>\n",
       "      <td>1747165616431</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21,316.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>467560</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367.2500</td>\n",
       "      <td>1.7531</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747165616263</td>\n",
       "      <td>1747165616263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-13 15:46:57.439000-04:00</th>\n",
       "      <td>1747165617439</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,315.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21,316.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>467571</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747165617263</td>\n",
       "      <td>1747165617255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-13 15:46:58.447000-04:00</th>\n",
       "      <td>1747165618447</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,316.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21,316.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1747165618208</td>\n",
       "      <td>1747165617904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69221 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      timestamp  key   bid_price   ask_price  \\\n",
       "datetime                                                                       \n",
       "2025-05-12 18:12:02.003000-04:00  1747087922003  /NQ 20,937.7500 20,939.7500   \n",
       "2025-05-12 18:12:03.026000-04:00  1747087923026  /NQ 20,939.5000 20,941.7500   \n",
       "2025-05-12 18:12:04.029000-04:00  1747087924029  /NQ 20,939.7500         NaN   \n",
       "2025-05-12 18:12:07.138000-04:00  1747087927138  /NQ         NaN         NaN   \n",
       "2025-05-12 18:12:08.161000-04:00  1747087928161  /NQ 20,940.7500 20,942.7500   \n",
       "...                                         ...  ...         ...         ...   \n",
       "2025-05-13 15:46:54.415000-04:00  1747165614415  /NQ 21,314.5000         NaN   \n",
       "2025-05-13 15:46:55.422000-04:00  1747165615422  /NQ 21,316.0000 21,316.5000   \n",
       "2025-05-13 15:46:56.431000-04:00  1747165616431  /NQ         NaN         NaN   \n",
       "2025-05-13 15:46:57.439000-04:00  1747165617439  /NQ 21,315.7500         NaN   \n",
       "2025-05-13 15:46:58.447000-04:00  1747165618447  /NQ 21,316.0000         NaN   \n",
       "\n",
       "                                  last_price bid_size ask_size total_volume  \\\n",
       "datetime                                                                      \n",
       "2025-05-12 18:12:02.003000-04:00 20,938.5000        1        1         1344   \n",
       "2025-05-12 18:12:03.026000-04:00 20,940.7500     None        4         1350   \n",
       "2025-05-12 18:12:04.029000-04:00 20,941.7500     None        3         1351   \n",
       "2025-05-12 18:12:07.138000-04:00 20,941.7500        3     None         None   \n",
       "2025-05-12 18:12:08.161000-04:00 20,942.5000        1        1         1362   \n",
       "...                                      ...      ...      ...          ...   \n",
       "2025-05-13 15:46:54.415000-04:00 21,314.5000        1        4       467548   \n",
       "2025-05-13 15:46:55.422000-04:00 21,316.2500        3        2       467554   \n",
       "2025-05-13 15:46:56.431000-04:00 21,316.0000        1        4       467560   \n",
       "2025-05-13 15:46:57.439000-04:00 21,316.0000        2     None       467571   \n",
       "2025-05-13 15:46:58.447000-04:00 21,316.0000        1        1         None   \n",
       "\n",
       "                                  last_size  high_price   low_price  \\\n",
       "datetime                                                              \n",
       "2025-05-12 18:12:02.003000-04:00          1 20,963.5000 20,931.7500   \n",
       "2025-05-12 18:12:03.026000-04:00          0         NaN         NaN   \n",
       "2025-05-12 18:12:04.029000-04:00          0         NaN         NaN   \n",
       "2025-05-12 18:12:07.138000-04:00          0         NaN         NaN   \n",
       "2025-05-12 18:12:08.161000-04:00          0         NaN         NaN   \n",
       "...                                     ...         ...         ...   \n",
       "2025-05-13 15:46:54.415000-04:00          0         NaN         NaN   \n",
       "2025-05-13 15:46:55.422000-04:00          0         NaN         NaN   \n",
       "2025-05-13 15:46:56.431000-04:00          0         NaN         NaN   \n",
       "2025-05-13 15:46:57.439000-04:00          0         NaN         NaN   \n",
       "2025-05-13 15:46:58.447000-04:00          0         NaN         NaN   \n",
       "\n",
       "                                  close_price  open_price  net_change  \\\n",
       "datetime                                                                \n",
       "2025-05-12 18:12:02.003000-04:00  20,136.7500 20,954.7500    801.7500   \n",
       "2025-05-12 18:12:03.026000-04:00          NaN         NaN    804.0000   \n",
       "2025-05-12 18:12:04.029000-04:00          NaN         NaN    805.0000   \n",
       "2025-05-12 18:12:07.138000-04:00          NaN         NaN         NaN   \n",
       "2025-05-12 18:12:08.161000-04:00          NaN         NaN    805.7500   \n",
       "...                                       ...         ...         ...   \n",
       "2025-05-13 15:46:54.415000-04:00          NaN         NaN         NaN   \n",
       "2025-05-13 15:46:55.422000-04:00          NaN         NaN    367.5000   \n",
       "2025-05-13 15:46:56.431000-04:00          NaN         NaN    367.2500   \n",
       "2025-05-13 15:46:57.439000-04:00          NaN         NaN         NaN   \n",
       "2025-05-13 15:46:58.447000-04:00          NaN         NaN         NaN   \n",
       "\n",
       "                                  future_pct_change open_interest   tick  \\\n",
       "datetime                                                                   \n",
       "2025-05-12 18:12:02.003000-04:00             3.9815        259062 0.2500   \n",
       "2025-05-12 18:12:03.026000-04:00             3.9927          None    NaN   \n",
       "2025-05-12 18:12:04.029000-04:00             3.9977          None    NaN   \n",
       "2025-05-12 18:12:07.138000-04:00                NaN          None    NaN   \n",
       "2025-05-12 18:12:08.161000-04:00             4.0014          None    NaN   \n",
       "...                                             ...           ...    ...   \n",
       "2025-05-13 15:46:54.415000-04:00                NaN          None    NaN   \n",
       "2025-05-13 15:46:55.422000-04:00             1.7543          None    NaN   \n",
       "2025-05-13 15:46:56.431000-04:00             1.7531          None    NaN   \n",
       "2025-05-13 15:46:57.439000-04:00                NaN          None    NaN   \n",
       "2025-05-13 15:46:58.447000-04:00                NaN          None    NaN   \n",
       "\n",
       "                                 tick_amount future_exp_date       ask_time  \\\n",
       "datetime                                                                      \n",
       "2025-05-12 18:12:02.003000-04:00           5   1750392000000  1747087921300   \n",
       "2025-05-12 18:12:03.026000-04:00        None            None  1747087922568   \n",
       "2025-05-12 18:12:04.029000-04:00        None            None  1747087923256   \n",
       "2025-05-12 18:12:07.138000-04:00        None            None           None   \n",
       "2025-05-12 18:12:08.161000-04:00        None            None  1747087927253   \n",
       "...                                      ...             ...            ...   \n",
       "2025-05-13 15:46:54.415000-04:00        None            None  1747165614255   \n",
       "2025-05-13 15:46:55.422000-04:00        None            None  1747165615257   \n",
       "2025-05-13 15:46:56.431000-04:00        None            None  1747165616263   \n",
       "2025-05-13 15:46:57.439000-04:00        None            None  1747165617263   \n",
       "2025-05-13 15:46:58.447000-04:00        None            None  1747165618208   \n",
       "\n",
       "                                       bid_time  \n",
       "datetime                                         \n",
       "2025-05-12 18:12:02.003000-04:00  1747087921227  \n",
       "2025-05-12 18:12:03.026000-04:00  1747087922893  \n",
       "2025-05-12 18:12:04.029000-04:00  1747087923707  \n",
       "2025-05-12 18:12:07.138000-04:00  1747087926812  \n",
       "2025-05-12 18:12:08.161000-04:00  1747087927281  \n",
       "...                                         ...  \n",
       "2025-05-13 15:46:54.415000-04:00  1747165614255  \n",
       "2025-05-13 15:46:55.422000-04:00  1747165615177  \n",
       "2025-05-13 15:46:56.431000-04:00  1747165616263  \n",
       "2025-05-13 15:46:57.439000-04:00  1747165617255  \n",
       "2025-05-13 15:46:58.447000-04:00  1747165617904  \n",
       "\n",
       "[69221 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>accumulative_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-12 18:12:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,938.5000</td>\n",
       "      <td>20,942.5000</td>\n",
       "      <td>20,938.5000</td>\n",
       "      <td>20,942.0000</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-12 18:13:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,942.0000</td>\n",
       "      <td>20,942.0000</td>\n",
       "      <td>20,934.7500</td>\n",
       "      <td>20,936.0000</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-12 18:14:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,936.0000</td>\n",
       "      <td>20,936.0000</td>\n",
       "      <td>20,932.5000</td>\n",
       "      <td>20,933.5000</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-12 18:15:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,933.5000</td>\n",
       "      <td>20,936.2500</td>\n",
       "      <td>20,932.2500</td>\n",
       "      <td>20,934.2500</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-12 18:16:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>20,933.5000</td>\n",
       "      <td>20,939.2500</td>\n",
       "      <td>20,927.7500</td>\n",
       "      <td>20,939.2500</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>2025-05-13 15:42:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,319.5000</td>\n",
       "      <td>21,330.0000</td>\n",
       "      <td>21,319.5000</td>\n",
       "      <td>21,330.0000</td>\n",
       "      <td>464744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>2025-05-13 15:43:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,329.2500</td>\n",
       "      <td>21,329.5000</td>\n",
       "      <td>21,321.7500</td>\n",
       "      <td>21,323.2500</td>\n",
       "      <td>465291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>2025-05-13 15:44:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,322.0000</td>\n",
       "      <td>21,324.0000</td>\n",
       "      <td>21,320.0000</td>\n",
       "      <td>21,322.5000</td>\n",
       "      <td>465782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>2025-05-13 15:45:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,322.5000</td>\n",
       "      <td>21,323.0000</td>\n",
       "      <td>21,311.7500</td>\n",
       "      <td>21,315.0000</td>\n",
       "      <td>466716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>2025-05-13 15:46:00-04:00</td>\n",
       "      <td>/NQ</td>\n",
       "      <td>21,313.5000</td>\n",
       "      <td>21,317.7500</td>\n",
       "      <td>21,309.5000</td>\n",
       "      <td>21,316.0000</td>\n",
       "      <td>467571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1295 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime ticker        open        high         low  \\\n",
       "0    2025-05-12 18:12:00-04:00    /NQ 20,938.5000 20,942.5000 20,938.5000   \n",
       "1    2025-05-12 18:13:00-04:00    /NQ 20,942.0000 20,942.0000 20,934.7500   \n",
       "2    2025-05-12 18:14:00-04:00    /NQ 20,936.0000 20,936.0000 20,932.5000   \n",
       "3    2025-05-12 18:15:00-04:00    /NQ 20,933.5000 20,936.2500 20,932.2500   \n",
       "4    2025-05-12 18:16:00-04:00    /NQ 20,933.5000 20,939.2500 20,927.7500   \n",
       "...                        ...    ...         ...         ...         ...   \n",
       "1290 2025-05-13 15:42:00-04:00    /NQ 21,319.5000 21,330.0000 21,319.5000   \n",
       "1291 2025-05-13 15:43:00-04:00    /NQ 21,329.2500 21,329.5000 21,321.7500   \n",
       "1292 2025-05-13 15:44:00-04:00    /NQ 21,322.0000 21,324.0000 21,320.0000   \n",
       "1293 2025-05-13 15:45:00-04:00    /NQ 21,322.5000 21,323.0000 21,311.7500   \n",
       "1294 2025-05-13 15:46:00-04:00    /NQ 21,313.5000 21,317.7500 21,309.5000   \n",
       "\n",
       "           close accumulative_volume  \n",
       "0    20,942.0000                1398  \n",
       "1    20,936.0000                1446  \n",
       "2    20,933.5000                1534  \n",
       "3    20,934.2500                1646  \n",
       "4    20,939.2500                1831  \n",
       "...          ...                 ...  \n",
       "1290 21,330.0000              464744  \n",
       "1291 21,323.2500              465291  \n",
       "1292 21,322.5000              465782  \n",
       "1293 21,315.0000              466716  \n",
       "1294 21,316.0000              467571  \n",
       "\n",
       "[1295 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key = 1\n",
    "\n",
    "tickers_list = list(ticker_tables.keys())\n",
    "display(minute_candles)\n",
    "display(tickers_list)\n",
    "display(ticker_tables[tickers_list[key]])\n",
    "display(minute_candles[tickers_list[key]])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
