{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c05d1f8",
   "metadata": {},
   "source": [
    "### <h3 style=\"color:yellow;\">Authentication for GBQ</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc34e65",
   "metadata": {},
   "source": [
    "Defines `config()` to return the service account key path for a given user (`reese` or `ben`); raises an error for others. Used for BigQuery authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_proj_id = 'stock-chipper-87578' \n",
    "\n",
    "def config(username=None):\n",
    "    if username == 'reese':\n",
    "        file_dir = \"C:/Users/rsmcd/OneDrive/Desktop/Trade Review/stock-chipper-research/\"\n",
    "        credential_file = 'stock-chipper-87578-ec8b427fca6a.json'\n",
    "    elif username == 'ben':\n",
    "        file_dir = \"C:/Users/benwo/Documents/repos/stock-chipper-app/creds/\"\n",
    "        credential_file = \"stock-chipper-87578-b17ad3f7e6e1.json\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized or missing username: {username}\")\n",
    "    \n",
    "    return file_dir + credential_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd8212",
   "metadata": {},
   "source": [
    "Selects user credentials based on context: uses CLI argument if run as `__main__`, defaults to `\"reese\"` otherwise. Falls back to `\"reese\"` on error. Result (`private_key`) is used for BigQuery authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1ba27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to default username (reese)\n"
     ]
    }
   ],
   "source": [
    "# Use default when in Jupyter or if __main__ but no args\n",
    "try:\n",
    "    if __name__ == \"__main__\":\n",
    "        if len(sys.argv) <= 1:\n",
    "            raise ValueError(\"No username provided via CLI args\")\n",
    "        private_key = config(sys.argv[1])\n",
    "    else:\n",
    "        private_key = config(\"reese\")  # Default for notebook\n",
    "except Exception as e:\n",
    "    print(\"Falling back to default username (reese)\")\n",
    "    private_key = config(\"reese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92aa7c",
   "metadata": {},
   "source": [
    "### <h3 style=\"color:yellow;\">Getting data from GBQ</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7c85c",
   "metadata": {},
   "source": [
    "Configuration and Directory Setup\n",
    "\n",
    "Defines key flags controlling the behavior of the script, such as whether to rebuild results, use local or remote data, and how many tickers to analyze. It also sets up directory paths for saving data, and ensures the necessary folders exist before proceeding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a942949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Flags\n",
    "get_ticker_list_from_gbq = True\n",
    "use_local_data_gbq = False\n",
    "build_results_gbq = True\n",
    "fresh_start_gbq = True\n",
    "num_to_test_gbq = 1 #schwab_ticker_num - 1  # If <0, use all\n",
    "output_stub_gbq = \"20240101_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: strategies\\swing-trading\\data\n"
     ]
    }
   ],
   "source": [
    "# Path setup\n",
    "DATA_DIR = Path(\"strategies/swing-trading/data\")\n",
    "WALK_FORWARD_DIR_SCHWAB = DATA_DIR / \"walk-forward-schwab\"                              ### Consider adding later (or sooner and do the data dirs at the same time) !!!\n",
    "WALK_FORWARD_DIR_GBQ = DATA_DIR / \"walk-forward-gbq\"\n",
    "MINUTE_TICKERS_FILE = DATA_DIR / \"tickers_random_index_list.txt\"\n",
    "\n",
    "# Delete the entire DATA_DIR folder and all its contents\n",
    "if DATA_DIR.exists() and DATA_DIR.is_dir():\n",
    "    shutil.rmtree(DATA_DIR)\n",
    "    print(f\"Deleted: {DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {DATA_DIR}\")\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WALK_FORWARD_DIR_SCHWAB.mkdir(parents=True, exist_ok=True)\n",
    "WALK_FORWARD_DIR_GBQ.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#MARKER# Make data storage directories here and move this block upstream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e3946",
   "metadata": {},
   "source": [
    "Load Ticker List\n",
    "\n",
    "Retrieves the list of tickers to analyze. If `get_ticker_list_from_gbq` is `True`, it queries BigQuery for tickers used in a recent backtesting window and adds a randomized index for sampling. Otherwise, it loads the list from a previously saved local file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e530373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull tickers from DB or local file\n",
    "if get_ticker_list_from_gbq:\n",
    "    # You'll need to implement this function to return a DataFrame\n",
    "    sql = '''\n",
    "        SELECT DISTINCT ticker \n",
    "        FROM main.tf_stocks_for_backtesting(\"2023-08-01\",\"2024-01-01\")\n",
    "    '''\n",
    "    all_tickers_gbq = run_sql_query(sql, project_id=gbq_proj_id, credentials_path=private_key) # placeholder\n",
    "    all_tickers_gbq[\"random_index\"] = random.sample(range(len(all_tickers_gbq)), len(all_tickers_gbq))\n",
    "    all_tickers_gbq.to_csv(MINUTE_TICKERS_FILE, sep=\"\\t\", index=False)\n",
    "else:\n",
    "    all_tickers_gbq = pd.read_csv(MINUTE_TICKERS_FILE, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d1cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>random_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLBZ</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIPT</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IGIC</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESCA</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCRH</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>TBI</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>DNB</td>\n",
       "      <td>2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>MP</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>DQ</td>\n",
       "      <td>3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>TARO</td>\n",
       "      <td>4203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4487 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker  random_index\n",
       "0      GLBZ          2501\n",
       "1      TIPT           464\n",
       "2      IGIC          1909\n",
       "3      ESCA          1603\n",
       "4      QCRH          1224\n",
       "...     ...           ...\n",
       "4482    TBI          2685\n",
       "4483    DNB          2145\n",
       "4484     MP          1627\n",
       "4485     DQ          3240\n",
       "4486   TARO          4203\n",
       "\n",
       "[4487 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_tickers_gbq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63bac46",
   "metadata": {},
   "source": [
    "Filter Tickers to Test\n",
    "\n",
    "Determines which tickers to include in the analysis. If `num_to_test` is greater than 0, it selects only those tickers with a `random_index` below the threshold. Otherwise, it includes all available tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tickers\n",
    "if num_to_test_gbq > 0:\n",
    "    tickers_to_test_gbq = all_tickers_gbq[all_tickers_gbq[\"random_index\"] <= num_to_test_gbq][\"ticker\"].tolist() + big_ticker_list\n",
    "else:\n",
    "    tickers_to_test_gbq = all_tickers_gbq[\"ticker\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BJRI', 'LSEA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tickers_to_test_gbq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3712748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_trading_day(current_date=None):\n",
    "    \"\"\"\n",
    "    Returns the most recent valid NYSE trading day before (or on) the given date.\n",
    "\n",
    "    This function checks the NYSE trading calendar for the last 30 days leading up to \n",
    "    `current_date` (or today, if not specified), and iterates backward to find the most \n",
    "    recent trading day. It accounts for weekends and market holidays.\n",
    "\n",
    "    Args:\n",
    "        current_date (datetime.date, optional): The reference date. Defaults to today.\n",
    "\n",
    "    Returns:\n",
    "        datetime.date: The most recent valid trading day prior to `current_date`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no trading day is found within the past 20 calendar days.\n",
    "    \"\"\"\n",
    "    if current_date is None:                                                                 # Use today's date if none is provided\n",
    "        current_date = date.today()                                                          # Set current_date to today\n",
    "\n",
    "    nyse = mcal.get_calendar('NYSE')                                                         # Load NYSE trading calendar\n",
    "    schedule = nyse.valid_days(start_date=(current_date - timedelta(days=30)).isoformat(),   # Get list of valid trading days\n",
    "                               end_date=current_date.isoformat())                             # within the past 30 days\n",
    "    valid_days = [d.date() for d in schedule]                                                 # Convert schedule to list of date objects\n",
    "\n",
    "    for i in range(1, 21):                                                                    # Check the last 20 calendar days\n",
    "        candidate = current_date - timedelta(days=i)                                          # Go back one day at a time\n",
    "        if candidate in valid_days:                                                           # Return if the day is a valid trading day\n",
    "            return candidate                                                                  # Return most recent valid trading day\n",
    "    raise ValueError(\"Could not find recent trading day.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d308b",
   "metadata": {},
   "source": [
    "Set up walkforward analysis parameters for GBQ data, defining the number of periods, analysis/evaluation window lengths, and overall date range. It also handles fresh vs. resumed runs by optionally deleting existing result files and filtering tickers accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBQ Overall finish date: 2024-03-15 00:00:00\n",
      "GBQ Number of periods: 3\n",
      "GBQ Analysis period: 42 days, 0:00:00\n",
      "GBQ Evaluation period: 28 days, 0:00:00\n",
      "GBQ End of last analysis period: 2024-02-16 00:00:00\n",
      "GBQ Overall start date: 2023-10-13 00:00:00\n",
      "GBQ Expected min analysis days: 24\n"
     ]
    }
   ],
   "source": [
    "# fresh_start logic\n",
    "if build_results_gbq:\n",
    "    overall_finish_gbq = datetime.strptime('2024-03-15', '%Y-%m-%d') #get_most_recent_trading_day()\n",
    "    print(\"GBQ Overall finish date:\", overall_finish_gbq)\n",
    "\n",
    "    num_periods_gbq = 3\n",
    "    print(\"GBQ Number of periods:\", num_periods_gbq)\n",
    "\n",
    "    analysis_period_gbq = timedelta(days=6*7)\n",
    "    print(\"GBQ Analysis period:\", analysis_period_gbq)\n",
    "\n",
    "    evaluation_period_gbq = timedelta(days=4*7)\n",
    "    print(\"GBQ Evaluation period:\", evaluation_period_gbq)\n",
    "\n",
    "    end_of_last_analysis_period_gbq = overall_finish_gbq - evaluation_period_gbq\n",
    "    print(\"GBQ End of last analysis period:\", end_of_last_analysis_period_gbq)\n",
    "\n",
    "    overall_start_gbq = end_of_last_analysis_period_gbq - num_periods_gbq * analysis_period_gbq\n",
    "    print(\"GBQ Overall start date:\", overall_start_gbq)\n",
    "    \n",
    "    expected_min_analysis_days_gbq = 6 * 4\n",
    "    print(\"GBQ Expected min analysis days:\", expected_min_analysis_days_gbq)\n",
    "\n",
    "    if fresh_start_gbq:                                                                 # If a full reset is requested...\n",
    "        for file in WALK_FORWARD_DIR_GBQ.glob(\"*\"):                                    # Iterate over all files in the walk-forward directory\n",
    "            file.unlink()                                                          # Delete each file (clears previous results)\n",
    "    else:                                                                          # Otherwise, resume from where you left off\n",
    "        existing_files = [f.stem.replace(output_stub_gbq, \"\")                          # Get list of tickers that already have result files\n",
    "                        for f in WALK_FORWARD_DIR_GBQ.glob(\"*.txt\")]                   # Only look for .txt files matching previous outputs\n",
    "        tickers_to_test_gbq = [t for t in tickers_to_test_gbq if t not in existing_files]  # Remove tickers that already have results from the test list\n",
    "\n",
    "#MARKER# Transfer this to Schwab like logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9708814",
   "metadata": {},
   "source": [
    "Fetch daily data for each ticker from GBQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 00:45:56\n",
      "(1/7) Fetching data for BJRI\n",
      "(2/7) Fetching data for LSEA\n",
      "(3/7) Fetching data for AAPL\n",
      "(4/7) Fetching data for MSFT\n",
      "(5/7) Fetching data for GOOGL\n",
      "(6/7) Fetching data for AMZN\n",
      "(7/7) Fetching data for TSLA\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "candles_dict_gbq = {}\n",
    "num_tickers = len(tickers_to_test_gbq)\n",
    "\n",
    "for i, ticker in enumerate(tickers_to_test_gbq, start=1):\n",
    "    print(f\"({i}/{num_tickers}) Fetching data for {ticker}\")\n",
    "    candles_dict_gbq[ticker] = get_ticker_data(\n",
    "        ticker,\n",
    "        overall_start_gbq,\n",
    "        local=use_local_data_gbq,\n",
    "        credentials_path=private_key,\n",
    "        project_id=gbq_proj_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4096bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BJRI':     ticker   date_time    open    high     low   close       volume\n",
       " 0     BJRI  2023-10-16 22.5200 22.8300 22.2900 22.4600 313,796.0000\n",
       " 1     BJRI  2023-10-17 22.2600 23.9600 22.2600 23.9350 441,152.0000\n",
       " 2     BJRI  2023-10-18 23.7500 24.1500 23.5975 24.0800 294,400.0000\n",
       " 3     BJRI  2023-10-19 24.1100 24.7500 23.7100 24.0400 400,820.0000\n",
       " 4     BJRI  2023-10-20 24.3000 24.7450 23.8500 24.0400 266,268.0000\n",
       " ..     ...         ...     ...     ...     ...     ...          ...\n",
       " 100   BJRI  2024-03-11 36.9200 36.9200 35.8700 35.9800 197,697.0000\n",
       " 101   BJRI  2024-03-12 36.0500 36.8100 35.8200 36.4100  98,583.0000\n",
       " 102   BJRI  2024-03-13 36.2200 37.5050 36.2200 36.3620 274,622.0000\n",
       " 103   BJRI  2024-03-14 36.0600 36.2450 34.6500 35.0800 203,878.0000\n",
       " 104   BJRI  2024-03-15 34.8200 35.3400 34.3100 35.0800 189,804.0000\n",
       " \n",
       " [105 rows x 7 columns],\n",
       " 'LSEA':     ticker   date_time    open    high     low   close       volume\n",
       " 0     LSEA  2023-10-16  7.5100  7.5800  7.2950  7.3300 149,639.0000\n",
       " 1     LSEA  2023-10-17  7.3100  7.5000  7.2400  7.2700 153,630.0000\n",
       " 2     LSEA  2023-10-18  7.2400  7.2700  7.1000  7.1400 126,395.0000\n",
       " 3     LSEA  2023-10-19  7.1400  7.3800  7.0400  7.2200  81,239.0000\n",
       " 4     LSEA  2023-10-20  7.2300  7.3300  7.1600  7.2500  61,185.0000\n",
       " ..     ...         ...     ...     ...     ...     ...          ...\n",
       " 100   LSEA  2024-03-11 13.5900 13.7000 13.0200 13.2400 177,925.0000\n",
       " 101   LSEA  2024-03-12 13.1800 13.5300 13.0500 13.5200  43,919.0000\n",
       " 102   LSEA  2024-03-13 13.4500 13.8000 13.4500 13.7000 230,068.0000\n",
       " 103   LSEA  2024-03-14 13.5600 13.7500 12.3800 12.4500 160,271.0000\n",
       " 104   LSEA  2024-03-15 12.2700 12.6500 12.2700 12.4200 136,274.0000\n",
       " \n",
       " [105 rows x 7 columns],\n",
       " 'AAPL':     ticker   date_time     open     high      low    close          volume\n",
       " 0     AAPL  2023-10-16 176.7600 179.0750 176.5100 178.7300 43,569,395.0000\n",
       " 1     AAPL  2023-10-17 176.6700 178.4200 174.8000 176.9800 49,084,695.0000\n",
       " 2     AAPL  2023-10-18 175.5700 177.5750 175.1100 175.6800 45,455,000.0000\n",
       " 3     AAPL  2023-10-19 176.0000 177.8400 174.9100 175.2600 46,680,267.0000\n",
       " 4     AAPL  2023-10-20 175.3700 175.4200 172.6400 172.9700 50,918,965.0000\n",
       " ..     ...         ...      ...      ...      ...      ...             ...\n",
       " 100   AAPL  2024-03-11 172.9800 174.3800 172.0500 172.7900 39,731,144.0000\n",
       " 101   AAPL  2024-03-12 173.1900 174.0300 171.0100 173.2200 38,805,841.0000\n",
       " 102   AAPL  2024-03-13 172.8800 173.1850 170.7600 171.1700 32,839,689.0000\n",
       " 103   AAPL  2024-03-14 172.9100 174.3078 172.0500 173.0800 48,992,587.0000\n",
       " 104   AAPL  2024-03-15 171.1700 172.6000 170.2850 172.5600 53,204,339.0000\n",
       " \n",
       " [105 rows x 7 columns],\n",
       " 'MSFT':     ticker   date_time     open     high      low    close          volume\n",
       " 0     MSFT  2023-10-16 331.0500 336.1400 330.6000 333.1500 16,670,168.0000\n",
       " 1     MSFT  2023-10-17 329.5900 335.2000 327.4100 334.4000 13,424,839.0000\n",
       " 2     MSFT  2023-10-18 332.4900 335.5900 328.3000 331.7500 16,925,327.0000\n",
       " 3     MSFT  2023-10-19 332.2500 336.8800 330.0600 330.8121 18,893,047.0000\n",
       " 4     MSFT  2023-10-20 331.7700 331.9200 325.4500 326.9100 18,975,844.0000\n",
       " ..     ...         ...      ...      ...      ...      ...             ...\n",
       " 100   MSFT  2024-03-11 403.7700 405.6800 401.2600 404.5800  8,235,360.0000\n",
       " 101   MSFT  2024-03-12 407.6200 415.5700 406.7900 415.2600 11,214,806.0000\n",
       " 102   MSFT  2024-03-13 418.1700 418.1800 411.4500 415.2300  8,190,832.0000\n",
       " 103   MSFT  2024-03-14 420.1700 427.8200 417.9900 425.4900 19,912,572.0000\n",
       " 104   MSFT  2024-03-15 419.2900 422.6000 412.7900 416.4220 18,956,301.0000\n",
       " \n",
       " [105 rows x 7 columns],\n",
       " 'GOOGL':     ticker   date_time     open     high      low    close          volume\n",
       " 0    GOOGL  2023-10-16 138.1700 139.6300 137.9900 138.9800 20,867,532.0000\n",
       " 1    GOOGL  2023-10-17 138.5800 139.9000 137.1800 139.7100 19,079,335.0000\n",
       " 2    GOOGL  2023-10-18 139.4600 140.7200 137.3800 138.1400 19,457,174.0000\n",
       " 3    GOOGL  2023-10-19 138.5400 139.6600 137.3800 137.6100 20,326,973.0000\n",
       " 4    GOOGL  2023-10-20 137.2500 137.8700 135.0800 135.5000 19,758,000.0000\n",
       " ..     ...         ...      ...      ...      ...      ...             ...\n",
       " 100  GOOGL  2024-03-11 136.2000 139.0950 136.1300 137.7100 21,541,114.0000\n",
       " 101  GOOGL  2024-03-12 137.0100 139.3750 137.0100 138.4900 15,631,381.0000\n",
       " 102  GOOGL  2024-03-13 138.9900 141.0900 138.9900 139.8400 13,941,993.0000\n",
       " 103  GOOGL  2024-03-14 141.1900 143.5850 140.4550 143.1800 27,520,131.0000\n",
       " 104  GOOGL  2024-03-15 142.3800 143.1800 140.0300 141.2450 21,822,242.0000\n",
       " \n",
       " [105 rows x 7 columns],\n",
       " 'AMZN':     ticker   date_time     open     high      low    close          volume\n",
       " 0     AMZN  2023-10-16 130.6900 133.0700 130.4250 132.6000 36,148,203.0000\n",
       " 1     AMZN  2023-10-17 130.3600 132.5800 128.7100 131.1300 38,792,902.0000\n",
       " 2     AMZN  2023-10-18 129.8700 130.6699 127.5100 128.7500 34,944,296.0000\n",
       " 3     AMZN  2023-10-19 130.5500 132.2400 127.4700 128.0500 49,336,945.0000\n",
       " 4     AMZN  2023-10-20 128.0200 128.1700 124.8500 124.9800 46,682,633.0000\n",
       " ..     ...         ...      ...      ...      ...      ...             ...\n",
       " 100   AMZN  2024-03-11 174.4700 174.4700 171.4700 171.9700 18,584,260.0000\n",
       " 101   AMZN  2024-03-12 173.5200 176.7600 171.9800 175.3900 23,729,019.0000\n",
       " 102   AMZN  2024-03-13 175.9500 177.6200 175.5500 176.5700 19,286,533.0000\n",
       " 103   AMZN  2024-03-14 177.6900 179.5300 176.4650 178.8500 27,823,240.0000\n",
       " 104   AMZN  2024-03-15 176.6400 177.9300 173.9000 174.4300 33,082,080.0000\n",
       " \n",
       " [105 rows x 7 columns],\n",
       " 'TSLA':     ticker   date_time     open     high      low    close           volume\n",
       " 0     TSLA  2023-10-16 250.0500 255.3999 248.4800 253.6000  72,740,155.0000\n",
       " 1     TSLA  2023-10-17 250.1000 257.1830 247.0800 254.5999  77,356,185.0000\n",
       " 2     TSLA  2023-10-18 252.7500 254.6300 235.8500 244.7800  92,935,500.0000\n",
       " 3     TSLA  2023-10-19 225.8400 230.6100 216.7800 217.7700 129,420,917.0000\n",
       " 4     TSLA  2023-10-20 217.0100 218.8606 210.4200 212.0600 114,513,136.0000\n",
       " ..     ...         ...      ...      ...      ...      ...              ...\n",
       " 100   TSLA  2024-03-11 175.4800 182.8700 174.8000 177.8300  67,685,297.0000\n",
       " 101   TSLA  2024-03-12 177.7100 179.4300 172.4101 177.4700  68,542,438.0000\n",
       " 102   TSLA  2024-03-13 173.0500 176.0500 169.1500 169.5000  77,863,729.0000\n",
       " 103   TSLA  2024-03-14 167.7700 171.1700 160.5100 162.5000  92,417,809.0000\n",
       " 104   TSLA  2024-03-15 163.1600 165.1845 160.7600 163.5900  68,367,119.0000\n",
       " \n",
       " [105 rows x 7 columns]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(candles_dict_gbq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2becc2",
   "metadata": {},
   "source": [
    "### <h3 style=\"color:yellow;\">Running analysis on GBQ data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_analysis_structure_gbq(ticker, end_of_last_analysis_period, analysis_period, evaluation_period, num_periods):\n",
    "    \"\"\"\n",
    "    Constructs a DataFrame defining rolling analysis and evaluation periods for a given ticker.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Ticker symbol to assign to the generated rows.\n",
    "        end_of_last_analysis_period (datetime): The most recent analysis period end date.\n",
    "        analysis_period (timedelta): Duration of each analysis period.\n",
    "        evaluation_period (timedelta): Duration of each evaluation period following the analysis.\n",
    "        num_periods (int): Number of rolling periods to generate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with `num_periods` rows and the columns at the end of the function:\n",
    "    \"\"\"\n",
    "    analysis_period_starts = [                                                                 # Generate list of period start dates\n",
    "        end_of_last_analysis_period - analysis_period * i                                      # Each start is offset by i * analysis_period\n",
    "        for i in range(1, num_periods + 1)                                                      # For the last `num_periods` analysis windows\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame({                                                                         # Create base DataFrame for the analysis structure\n",
    "        \"ticker\": ticker,                                                                       # Set the ticker label\n",
    "        \"analysis_period_start\": pd.to_datetime(analysis_period_starts),                        # Assign start dates for each analysis period\n",
    "    })\n",
    "\n",
    "    df[\"analysis_period_end\"] = df[\"analysis_period_start\"] + analysis_period                   # Calculate the end of each analysis period\n",
    "    df[\"analysis_buy\"] = 0.0                                                                    # Initialize buy threshold column\n",
    "    df[\"analysis_sell\"] = 0.0                                                                   # Initialize sell threshold column\n",
    "    df[\"analysis_return\"] = 0.0                                                                 # Initialize return column for analysis period\n",
    "    df[\"analysis_trades\"] = 0                                                                   # Initialize number of trades in analysis period\n",
    "    df[\"analysis_eval_metric\"] = 0.0                                                            # Initialize penalized evaluation metric column\n",
    "    df[\"evaluation_period_start\"] = df[\"analysis_period_end\"] + timedelta(days=1)              # Evaluation starts the day after analysis ends\n",
    "    df[\"evaluation_period_end\"] = df[\"evaluation_period_start\"] + evaluation_period             # Evaluation end is offset from its start\n",
    "    df[\"evaluation_return\"] = 0.0                                                               # Initialize evaluation return column\n",
    "    df[\"evaluation_trades\"] = 0                                                                 # Initialize evaluation trade count\n",
    "    df[\"evaluation_data_good\"] = False                                                          # Flag whether evaluation data exists\n",
    "\n",
    "    return df                                                                                   # Return the prepared DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0e3da",
   "metadata": {},
   "source": [
    "Builds the base results structure for each GBQ ticker by generating rolling analysis and evaluation windows using `prepare_analysis_structure()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build the base results structure\n",
    "results_structure_dict_gbq = {}\n",
    "num_tickers_gbq = len(tickers_to_test_gbq)\n",
    "\n",
    "# Prepare the analysis structure for each ticker\n",
    "for i, ticker in enumerate(tickers_to_test_gbq, start=1):\n",
    "    print(f\"({i}/{num_tickers_gbq}) Preparing analysis structure for {ticker}\")\n",
    "    results_structure_dict_gbq[ticker] = prepare_analysis_structure_gbq(\n",
    "        ticker,\n",
    "        end_of_last_analysis_period_gbq,\n",
    "        analysis_period_gbq,\n",
    "        evaluation_period_gbq,\n",
    "        num_periods_gbq\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59708f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_structure_dict_gbq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tickers_schwab = len(tickers_to_test_schwab)\n",
    "for i, ticker in enumerate(tickers_to_test_schwab, start=1):\n",
    "    print(f\"({i}/{num_tickers_schwab}) Preparing analysis structure for {ticker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0649fa3",
   "metadata": {},
   "source": [
    "Runs the walk-forward optimization and evaluation loop for each GBQ ticker and stores the updated results in `final_results_dict_gbq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "final_results_dict_gbq = {}\n",
    "num_tickers_gbq = len(tickers_to_test_gbq)\n",
    "\n",
    "# Run the analysis and evaluation loop for each ticker\n",
    "for i, ticker in enumerate(tickers_to_test_gbq, start=1):\n",
    "    print(f\"({i}/{num_tickers_gbq}) Running analysis loop for {ticker}\")\n",
    "    final_results_dict_gbq[ticker] = run_analysis_loop(\n",
    "        results_structure_dict_gbq[ticker],\n",
    "        candles_dict_gbq[ticker],\n",
    "        expected_min_analysis_days_gbq\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6064a6d",
   "metadata": {},
   "source": [
    "Taking a look at GBQ analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict items to a list to enable index-based access\n",
    "final_results_list = list(final_results_dict_gbq.items())\n",
    "\n",
    "# Example: display the DataFrame at index 0\n",
    "ticker, df = final_results_list[0]\n",
    "print(f\"Ticker: {ticker}\")\n",
    "display(df)\n",
    "display(final_results_dict_gbq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b09cce",
   "metadata": {},
   "source": [
    "Save GBQ results to disk and print performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8722bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ticker in enumerate(tickers_to_test_gbq, start=1):\n",
    "    output_file = f\"{output_stub_gbq}{ticker}.txt\"\n",
    "    output_path = WALK_FORWARD_DIR_GBQ / output_file\n",
    "    final_results_dict_gbq[ticker].to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "    print(f\"({i}/{num_tickers_gbq}) Completed {ticker}\")\n",
    "    recent_eval = evaluate_recent_performance(final_results_dict_gbq[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_periods_gbq == 1 and analysis_ratio_gbq == 1:\n",
    "    final_results_dict_gbq = add_analysis_metrics(final_results_dict_gbq, candles_dict_gbq)\n",
    "    display(final_results_dict_gbq)\n",
    "\n",
    "if num_periods_gbq == 1 and analysis_ratio_gbq == 1:\n",
    "    final_results_df_gbq = pd.concat(final_results_dict_gbq.values(), ignore_index=True)\n",
    "    print(\"Concatenated results for single period analysis.\")\n",
    "    final_results_df_gbq.to_csv(WALK_FORWARD_DIR_GBQ / \"final_results_df_gbq.csv\", sep=\"\\t\", index=False)\n",
    "    display(final_results_df_gbq)\n",
    "else: print(\"Multiple periods detected, skipping concatenation.\")\n",
    "\n",
    "MARKER# CONTINUE WORKING ON THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cbb73",
   "metadata": {},
   "source": [
    "### <h3 style=\"color:yellow;\">Monolithic Schwab Functions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4432be",
   "metadata": {},
   "source": [
    "Old monolithic, complex `add_analysis_metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bdce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_analysis_metrics(results_dict, price_data_dict):\n",
    "#     \"\"\"\n",
    "#     Adds analytics columns to each DataFrame in results_dict using the associated OHLCV data.\n",
    "\n",
    "#     Parameters:\n",
    "#     - results_dict (dict): Maps tickers to DataFrames of walk-forward analysis results.\n",
    "#     - price_data_dict (dict): Maps tickers to their full OHLCV DataFrames with 'date_time', 'high', 'low', 'close'.\n",
    "\n",
    "#     Returns:\n",
    "#     - dict: Updated results_dict with new columns added.\n",
    "#     \"\"\"\n",
    "#     updated_results = {}\n",
    "\n",
    "#     for ticker, df in results_dict.items():\n",
    "#         prices = price_data_dict[ticker].copy()\n",
    "#         prices[\"date_time\"] = pd.to_datetime(prices[\"date_time\"])\n",
    "#         last_close = prices[\"close\"].iloc[-1]\n",
    "\n",
    "#         df = df.copy()\n",
    "#         df[\"current_price_below_lb\"] = df[\"analysis_buy\"].apply(\n",
    "#             lambda lb: last_close < lb if pd.notnull(lb) else np.nan\n",
    "#         )\n",
    "#         df[\"percent_below_lb\"] = df[\"analysis_buy\"].apply(\n",
    "#             lambda lb: (lb - last_close) / lb if pd.notnull(lb) else np.nan\n",
    "#         )\n",
    "#         df[\"current_price_below_ub\"] = df[\"analysis_sell\"].apply(\n",
    "#             lambda ub: last_close < ub if pd.notnull(ub) else np.nan\n",
    "#         )\n",
    "#         df[\"percent_below_ub\"] = df[\"analysis_sell\"].apply(\n",
    "#             lambda ub: (ub - last_close) / ub if pd.notnull(ub) else np.nan\n",
    "#         )\n",
    "#         df[\"current_price_between_bounds\"] = df.apply(\n",
    "#             lambda row: (\n",
    "#                 row[\"analysis_buy\"] < last_close < row[\"analysis_sell\"]\n",
    "#                 if pd.notnull(row[\"analysis_buy\"]) and pd.notnull(row[\"analysis_sell\"])\n",
    "#                 else np.nan\n",
    "#             ),\n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#         num_days_lb_list = []\n",
    "#         num_days_ub_list = []\n",
    "#         trend_slope_list = []\n",
    "#         norm_trend_slope_list = []\n",
    "\n",
    "#         for _, row in df.iterrows():\n",
    "#             lb = row[\"analysis_buy\"]\n",
    "#             ub = row[\"analysis_sell\"]\n",
    "#             start_date = pd.to_datetime(row[\"analysis_period_start\"])\n",
    "#             end_date = pd.to_datetime(row[\"analysis_period_end\"])\n",
    "\n",
    "#             analysis_period = prices[\n",
    "#                 (prices[\"date_time\"] >= start_date) &\n",
    "#                 (prices[\"date_time\"] <= end_date)\n",
    "#             ].copy()\n",
    "\n",
    "#             analysis_period = analysis_period.sort_values(\"date_time\", ascending=False)\n",
    "\n",
    "#             # Days below lb\n",
    "#             if pd.notnull(lb):\n",
    "#                 count_lb = 0\n",
    "#                 for _, candle in analysis_period.iterrows():\n",
    "#                     if candle[\"high\"] < lb and candle[\"low\"] < lb:\n",
    "#                         count_lb += 1\n",
    "#                     else:\n",
    "#                         break\n",
    "#                 num_days_lb_list.append(count_lb)\n",
    "#             else:\n",
    "#                 num_days_lb_list.append(np.nan)\n",
    "\n",
    "#             # Days below ub\n",
    "#             if pd.notnull(ub):\n",
    "#                 count_ub = 0\n",
    "#                 for _, candle in analysis_period.iterrows():\n",
    "#                     if candle[\"high\"] < ub and candle[\"low\"] < ub:\n",
    "#                         count_ub += 1\n",
    "#                     else:\n",
    "#                         break\n",
    "#                 num_days_ub_list.append(count_ub)\n",
    "#             else:\n",
    "#                 num_days_ub_list.append(np.nan)\n",
    "\n",
    "#             # Trend slope (raw and normalized) using real time\n",
    "#             if len(analysis_period) >= 2:\n",
    "#                 closes = analysis_period[\"close\"].values\n",
    "#                 x = mdates.date2num(analysis_period[\"date_time\"])  # use real time axis\n",
    "#                 slope, _, _, _, _ = linregress(x, closes)\n",
    "#                 trend_slope_list.append(slope)\n",
    "#                 norm_slope = slope / closes.mean() if closes.mean() != 0 else 0\n",
    "#                 norm_trend_slope_list.append(norm_slope)\n",
    "#             else:\n",
    "#                 trend_slope_list.append(np.nan)\n",
    "#                 norm_trend_slope_list.append(np.nan)\n",
    "\n",
    "#         df[\"num_days_below_lb\"] = num_days_lb_list\n",
    "#         df[\"num_days_below_ub\"] = num_days_ub_list\n",
    "#         df[\"trend_slope\"] = trend_slope_list\n",
    "#         df[\"norm_trend_slope\"] = norm_trend_slope_list  # For scoring\n",
    "\n",
    "#         # Cyclicality measure\n",
    "#         full_prices = prices.set_index(\"date_time\")\n",
    "#         full_span = full_prices[\"high\"].max() - full_prices[\"low\"].min()\n",
    "#         avg_day_range = (full_prices[\"high\"] - full_prices[\"low\"]).mean()\n",
    "#         cyclicality_ratio = avg_day_range / full_span if full_span != 0 else np.nan\n",
    "#         df[\"cyclicality\"] = cyclicality_ratio\n",
    "\n",
    "#         updated_results[ticker] = df\n",
    "\n",
    "#     return updated_results\n",
    "\n",
    "# if num_periods_schwab == 1 and analysis_ratio_schwab == 1:\n",
    "#     final_results_dict_schwab = add_analysis_metrics(final_results_dict_schwab, candles_dict_schwab)\n",
    "#     display(final_results_dict_schwab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565f3db",
   "metadata": {},
   "source": [
    "Old monolithic complex version of `score_profit_probability`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587399e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_profit_probability(results_dict, weights=None, bound_reference=\"upper\"):\n",
    "#     \"\"\"\n",
    "#     Adds a profit probability score, ranking, and swing probability category to each DataFrame in a results dictionary.\n",
    "#     Also records the weight values used into each DataFrame as columns.\n",
    "\n",
    "#     Parameters:\n",
    "#     - results_dict (dict): Dictionary of {ticker: pd.DataFrame} with analysis results.\n",
    "#     - weights (dict, optional): Weights for each scoring component.\n",
    "#     - bound_reference (str): Either \"lower\" or \"upper\" to indicate which bound to use for scoring.\n",
    "\n",
    "#     Returns:\n",
    "#     - dict: Updated results_dict with 'profit_score', 'profit_rank', 'swing_probability', and weight columns.\n",
    "#     \"\"\"\n",
    "#     if bound_reference not in {\"lower\", \"upper\"}:\n",
    "#         raise ValueError(\"bound_reference must be either 'lower' or 'upper'\")\n",
    "\n",
    "#     suffix = \"lb\" if bound_reference == \"lower\" else \"ub\"\n",
    "\n",
    "#     if weights is None:\n",
    "#         weights = {\n",
    "#             f\"current_price_below_{suffix}\": 1.0,\n",
    "#             f\"percent_below_{suffix}\": 0.25,\n",
    "#             f\"num_days_below_{suffix}\": 0.0,\n",
    "#             \"cyclicality\": 0.75,\n",
    "#             \"norm_trend_slope\": 1.75  # ✅ New metric\n",
    "#         }\n",
    "\n",
    "#     combined_df = pd.concat(results_dict.values(), ignore_index=True)\n",
    "#     combined_df[f\"current_price_below_{suffix}\"] = combined_df[f\"current_price_below_{suffix}\"].astype(float)\n",
    "\n",
    "#     # Rank components\n",
    "#     combined_df[\"_rank_percent\"] = combined_df[f\"percent_below_{suffix}\"].rank(pct=True)\n",
    "#     combined_df[\"_rank_days\"] = combined_df[f\"num_days_below_{suffix}\"].rank(pct=True)\n",
    "#     combined_df[\"_rank_cyclicality\"] = combined_df[\"cyclicality\"].rank(pct=True)\n",
    "#     combined_df[\"_rank_trend\"] = combined_df[\"norm_trend_slope\"].rank(pct=True)\n",
    "\n",
    "#     current_mask = combined_df[f\"current_price_below_{suffix}\"]\n",
    "\n",
    "#     # Final score\n",
    "#     combined_df[\"profit_score\"] = current_mask * (\n",
    "#         weights.get(f\"current_price_below_{suffix}\", 0) +\n",
    "#         combined_df[\"_rank_percent\"] * weights.get(f\"percent_below_{suffix}\", 0) +\n",
    "#         combined_df[\"_rank_days\"] * weights.get(f\"num_days_below_{suffix}\", 0) +\n",
    "#         combined_df[\"_rank_cyclicality\"] * weights.get(\"cyclicality\", 0) +\n",
    "#         combined_df[\"_rank_trend\"] * weights.get(\"norm_trend_slope\", 0)\n",
    "#     )\n",
    "\n",
    "#     combined_df[\"profit_rank\"] = combined_df[\"profit_score\"].rank(ascending=False)\n",
    "\n",
    "#     # Swing category\n",
    "#     swing_probs = pd.Series(index=combined_df.index, dtype=\"object\")\n",
    "#     nonzero_scores = combined_df[combined_df[\"profit_score\"] > 0]\n",
    "#     percentiles = nonzero_scores[\"profit_score\"].rank(pct=True)\n",
    "\n",
    "#     for idx, p in percentiles.items():\n",
    "#         if p <= 0.2:\n",
    "#             swing_probs[idx] = \"very_low\"\n",
    "#         elif p <= 0.4:\n",
    "#             swing_probs[idx] = \"low\"\n",
    "#         elif p <= 0.6:\n",
    "#             swing_probs[idx] = \"medium\"\n",
    "#         elif p <= 0.8:\n",
    "#             swing_probs[idx] = \"high\"\n",
    "#         else:\n",
    "#             swing_probs[idx] = \"very_high\"\n",
    "\n",
    "#     swing_probs[combined_df[\"profit_score\"] == 0] = \"zero\"\n",
    "#     combined_df[\"swing_probability\"] = swing_probs\n",
    "\n",
    "#     # Clean up\n",
    "#     combined_df.drop(columns=[\"_rank_percent\", \"_rank_days\", \"_rank_cyclicality\", \"_rank_trend\"], inplace=True)\n",
    "\n",
    "#     # Return results\n",
    "#     row_counter = 0\n",
    "#     for ticker, df in results_dict.items():\n",
    "#         num_rows = len(df)\n",
    "#         updated_chunk = combined_df.iloc[row_counter:row_counter + num_rows]\n",
    "\n",
    "#         # Assign core results\n",
    "#         df[\"profit_score\"] = updated_chunk[\"profit_score\"].values\n",
    "#         df[\"profit_rank\"] = updated_chunk[\"profit_rank\"].values\n",
    "#         df[\"swing_probability\"] = updated_chunk[\"swing_probability\"].values\n",
    "\n",
    "#         # Assign weights as constant columns\n",
    "#         for key, val in weights.items():\n",
    "#             df[key + \"_weight\"] = val\n",
    "\n",
    "#         row_counter += num_rows\n",
    "\n",
    "#     return results_dict\n",
    "\n",
    "# bound_reference_schwab = \"lower\"  # Choose either \"lower\" or \"upper\" bound for scoring\n",
    "\n",
    "# if num_periods_schwab == 1 and analysis_ratio_schwab == 1:\n",
    "#     final_results_dict_schwab = score_profit_probability(final_results_dict_schwab, weights=None, bound_reference=bound_reference_schwab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89471939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_trades(data, upper_bound, lower_bound, time_start):\n",
    "#     \"\"\"\n",
    "#     Simulates a basic swing trading strategy using high/low breakouts.\n",
    "\n",
    "#     Iterates over a DataFrame of daily OHLC data to identify buy and sell trades:\n",
    "#     - A **buy** occurs when the low of the day falls below or equals the `lower_bound`.\n",
    "#     - A **sell** occurs when the high of the day rises above or equals the `upper_bound`.\n",
    "#     - Only one position can be held at a time.\n",
    "#     - If the end of the data is reached while a position is open, it is force-closed \n",
    "#       at the midpoint of the final day's high and low.\n",
    "\n",
    "#     Args:\n",
    "#         data (pd.DataFrame): Daily OHLC data with columns ['date_time', 'high', 'low'].\n",
    "#         upper_bound (float): The price level that triggers a sell.\n",
    "#         lower_bound (float): The price level that triggers a buy.\n",
    "#         time_start (datetime-like): Trades are only evaluated for rows on or after this timestamp.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: A DataFrame of executed trades with columns:\n",
    "#             ['date', 'type', 'daily_high', 'daily_low', 'trade_price']\n",
    "#     \"\"\"\n",
    "#     time_start = pd.to_datetime(time_start)  # Ensure compatible type for comparison\n",
    "#     data = data.copy()\n",
    "#     data[\"date_time\"] = pd.to_datetime(data[\"date_time\"])    \n",
    "#     state = 0                                                                                     # 0 = not in position, 1 = in position\n",
    "#     trades = []                                                                                   # List to store executed trades\n",
    "\n",
    "#     for i, row in data.iterrows():                                                                # Iterate over each row in the data\n",
    "#         if row[\"date_time\"] < time_start:                                                         # Skip rows before the time_start threshold\n",
    "#             continue                                                                              # Move to the next row\n",
    "\n",
    "#         if state == 0 and row[\"low\"] <= lower_bound:                                              # Entry condition: not in position and price hits or drops below lower bound\n",
    "#             trades.append({                                                                       # Record a buy trade\n",
    "#                 \"date\": row[\"date_time\"],                                                         # Trade date\n",
    "#                 \"type\": \"buy\",                                                                    # Trade type\n",
    "#                 \"daily_high\": row[\"high\"],                                                        # High of the day\n",
    "#                 \"daily_low\": row[\"low\"],                                                          # Low of the day\n",
    "#                 \"trade_price\": lower_bound                                                        # Executed price at lower bound\n",
    "#             })\n",
    "#             state = 1                                                                             # Update state to indicate we are now in a position\n",
    "#         elif state == 1 and row[\"high\"] >= upper_bound:                                           # Exit condition: in position and price rises above upper bound\n",
    "#             trades.append({                                                                       # Record a sell trade\n",
    "#                 \"date\": row[\"date_time\"],                                                         # Trade date\n",
    "#                 \"type\": \"sell\",                                                                   # Trade type\n",
    "#                 \"daily_high\": row[\"high\"],                                                        # High of the day\n",
    "#                 \"daily_low\": row[\"low\"],                                                          # Low of the day\n",
    "#                 \"trade_price\": upper_bound                                                        # Executed price at upper bound\n",
    "#             })\n",
    "#             state = 0                                                                             # Update state to indicate we're out of position\n",
    "\n",
    "#     if state == 1:                                                                                # If still in position at the end, force close\n",
    "#         last = data.iloc[-1]                                                                      # Get the last row in the data\n",
    "#         trades.append({                                                                           # Record a forced sell trade\n",
    "#             \"date\": last[\"date_time\"],                                                            # Trade date\n",
    "#             \"type\": \"sell\",                                                                       # Trade type\n",
    "#             \"daily_high\": last[\"high\"],                                                           # High of the day\n",
    "#             \"daily_low\": last[\"low\"],                                                             # Low of the day\n",
    "#             \"trade_price\": 0.5 * (last[\"high\"] + last[\"low\"])                                     # Forced close price is midpoint between high and low\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(trades)                                                                   # Convert list of trades to a DataFrame and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cee2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_returns(data, upper_bound, lower_bound, time_start, starting_cash=10000):\n",
    "#     \"\"\"\n",
    "#     Simulates a swing trading strategy and calculates the annualized return.\n",
    "\n",
    "#     Executes trades based on breakout conditions using `get_trades()`:\n",
    "#     - Buys when price hits `lower_bound`\n",
    "#     - Sells when price hits `upper_bound`\n",
    "#     - Assumes full portfolio allocation on each trade (no partial positions)\n",
    "#     - Closes the final position at the end of the data if still open\n",
    "\n",
    "#     Computes:\n",
    "#     - The total number of buy-side trades\n",
    "#     - The annualized return over the trading period\n",
    "\n",
    "#     Args:\n",
    "#         data (pd.DataFrame): Daily OHLC data with columns ['date_time', 'high', 'low'].\n",
    "#         upper_bound (float): Price level that triggers a sell.\n",
    "#         lower_bound (float): Price level that triggers a buy.\n",
    "#         time_start (datetime-like): The start date for evaluating trades.\n",
    "#         starting_cash (float): Initial portfolio cash. Defaults to 10,000.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: {\n",
    "#             \"annualized_return\" (float or None): Annualized percentage return,\n",
    "#                 or None if no trades were executed or time span is 0.\n",
    "#             \"num_trades\" (int): Number of completed buy trades.\n",
    "#         }\n",
    "#     \"\"\"\n",
    "#     trades = get_trades(data, upper_bound, lower_bound, time_start)                             # Run the trade simulation using breakout rules\n",
    "\n",
    "#     if trades.empty:                                                                            # If no trades occurred, return early\n",
    "#         return {\"annualized_return\": None, \"num_trades\": 0}                                     # Return None and 0 trades if no signals\n",
    "\n",
    "#     shares = 0                                                                                  # Initialize position size\n",
    "#     cash = starting_cash                                                                        # Start with the full cash amount\n",
    "\n",
    "#     for _, trade in trades.iterrows():                                                          # Loop through the trades chronologically\n",
    "#         if trade[\"type\"] == \"buy\":                                                              # If it's a buy trade\n",
    "#             shares = cash / trade[\"trade_price\"]                                                # Allocate entire portfolio into shares\n",
    "#             cash = 0                                                                            # Cash is now fully deployed\n",
    "#         elif trade[\"type\"] == \"sell\":                                                           # If it's a sell trade\n",
    "#             cash = shares * trade[\"trade_price\"]                                                # Liquidate shares to get cash\n",
    "#             shares = 0                                                                          # No position remains\n",
    "\n",
    "#     last_day = pd.to_datetime(data[\"date_time\"].max())  \n",
    "#     time_start = pd.to_datetime(time_start)                                                          # Last available date in the data\n",
    "#     period_years = (last_day - time_start).days / 365.25                        # Duration of trading period in years\n",
    "\n",
    "#     if period_years == 0:                                                                       # Edge case: zero duration (e.g., same-day trades)\n",
    "#         return {\"annualized_return\": None, \"num_trades\": trades['type'].eq(\"buy\").sum()}        # Avoid divide-by-zero; return None safely\n",
    "\n",
    "#     total_return = cash / starting_cash - 1                                                     # Compute simple return (final / initial - 1)\n",
    "#     annualized = (cash / starting_cash) ** (1 / period_years) - 1                               # Convert total return to annualized return\n",
    "\n",
    "#     return {\"total_return\": total_return, \"annualized_return\": annualized, \"num_trades\": trades['type'].eq(\"buy\").sum()}      # Return final results as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_analysis_loop(ticker_results, daily_data, expected_min_analysis_days):                          # Perform optimization and evaluation for each analysis/evaluation period\n",
    "#     \"\"\"\n",
    "#     Performs optimization and evaluation for each row in the walk-forward results DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         ticker_results (pd.DataFrame): Table with period metadata and signal slots for a single ticker.\n",
    "#         daily_data (pd.DataFrame): OHLCV data with a 'date_time' column.\n",
    "#         expected_min_analysis_days (int): Minimum number of days required to consider an analysis window valid.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: Updated ticker_results with optimized thresholds and evaluation performance filled in.\n",
    "#     \"\"\"\n",
    "#     for idx, row in ticker_results.iterrows():                                                           # Iterate through each row (period) of the ticker results table\n",
    "#         analysis_data = daily_data[                                                                      # Slice the data for the current analysis window\n",
    "#             (daily_data[\"date_time\"] >= row[\"analysis_period_start\"]) &                                  # Include data on or after the analysis start\n",
    "#             (daily_data[\"date_time\"] <= row[\"analysis_period_end\"])                                      # And on or before the analysis end\n",
    "#         ]\n",
    "\n",
    "#         if len(analysis_data) < expected_min_analysis_days:                                              # Skip this window if not enough trading days\n",
    "#             continue\n",
    "\n",
    "#         evaluation_data = daily_data[                                                                    # Slice the data for the evaluation window\n",
    "#             (daily_data[\"date_time\"] >= row[\"evaluation_period_start\"]) &                                # Include data on or after the evaluation start\n",
    "#             (daily_data[\"date_time\"] <= row[\"evaluation_period_end\"])                                    # And on or before the evaluation end\n",
    "#         ]\n",
    "\n",
    "#         if not analysis_data.empty:                                                                       # Proceed if there's valid analysis data\n",
    "#             period_results = analyze_ticker_data(analysis_data)                                           # Run optimization for buy/sell thresholds\n",
    "\n",
    "# ################################################### NEW CODE BLOCK ##################################################\n",
    "#             analysis_trades = get_trades(analysis_data, period_results[\"ub\"][0], period_results[\"lb\"][0], row[\"analysis_period_start\"])\n",
    "#             buy_sell_pairs = analysis_trades[analysis_trades[\"type\"].isin([\"buy\", \"sell\"])]\n",
    "#             if len(buy_sell_pairs) >= 2:\n",
    "#                 durations = buy_sell_pairs[\"date\"].diff().dropna().dt.days\n",
    "#                 ticker_results.at[idx, \"analysis_avg_trade_duration\"] = durations[::2].mean()\n",
    "#             else:\n",
    "#                 ticker_results.at[idx, \"analysis_avg_trade_duration\"] = np.nan\n",
    "# ################################################### NEW CODE BLOCK ##################################################\n",
    "\n",
    "#             ticker_results.at[idx, \"analysis_buy\"] = period_results[\"lb\"][0]                              # Save optimized lower bound (buy threshold)\n",
    "#             ticker_results.at[idx, \"analysis_sell\"] = period_results[\"ub\"][0]                             # Save optimized upper bound (sell threshold)\n",
    "#             ticker_results.at[idx, \"analysis_return\"] = period_results[\"return\"][0]                       # Save annualized return for this config\n",
    "#             ticker_results.at[idx, \"analysis_trades\"] = period_results[\"trades\"][0]                       # Save number of trades\n",
    "#             ticker_results.at[idx, \"analysis_eval_metric\"] = period_results[\"return_lb\"][0]              # Save penalized return metric\n",
    "#         else:\n",
    "#             ticker_results.at[idx, \"analysis_return\"] = np.nan                                            # If no data, store NaN as placeholder\n",
    "\n",
    "#         if not evaluation_data.empty:                                                                     # Proceed if there's evaluation data\n",
    "#             ticker_results.at[idx, \"evaluation_data_good\"] = True                                         # Mark the data as usable\n",
    "\n",
    "#             eval_results = get_returns(\n",
    "#                 evaluation_data,\n",
    "#                 upper_bound=ticker_results.at[idx, \"analysis_sell\"],\n",
    "#                 lower_bound=ticker_results.at[idx, \"analysis_buy\"],\n",
    "#                 time_start=ticker_results.at[idx, \"evaluation_period_start\"]\n",
    "#             )\n",
    "\n",
    "# ################################################## NEW CODE BLOCK ##################################################\n",
    "#             eval_trades = get_trades(evaluation_data, ticker_results.at[idx, \"analysis_sell\"], ticker_results.at[idx, \"analysis_buy\"], row[\"evaluation_period_start\"])\n",
    "#             buy_sell_pairs = eval_trades[eval_trades[\"type\"].isin([\"buy\", \"sell\"])]\n",
    "#             if len(buy_sell_pairs) >= 2:\n",
    "#                 durations = buy_sell_pairs[\"date\"].diff().dropna().dt.days\n",
    "#                 ticker_results.at[idx, \"evaluation_avg_trade_duration\"] = durations[::2].mean()\n",
    "#             else:\n",
    "#                 ticker_results.at[idx, \"evaluation_avg_trade_duration\"] = np.nan\n",
    "# ################################################## NEW CODE BLOCK ##################################################\n",
    "\n",
    "#             ticker_results.at[idx, \"evaluation_trades\"] = eval_results[\"num_trades\"]                      # Store number of trades during evaluation\n",
    "#             ticker_results.at[idx, \"evaluation_return\"] = eval_results[\"annualized_return\"]               # Store annualized return during evaluation\n",
    "\n",
    "#     return ticker_results                                                                                 # Return the updated DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23672025",
   "metadata": {},
   "source": [
    "Pull all data and include exchange info from Schwab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40217dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")) # Revert to this working block 1111\n",
    "\n",
    "# all_candles_combined = []\n",
    "# num_tickers = len(test_tickers_df)\n",
    "# print(num_tickers)\n",
    "\n",
    "# for i, (_, row) in enumerate(test_tickers_df.iterrows(), start=1):\n",
    "#     ticker = row['ticker']\n",
    "#     exchange = row['exchange']\n",
    "\n",
    "#     # print(f\"[{i}/{num_tickers}] Fetching {ticker} ({exchange})...\")\n",
    "    \n",
    "#     try:\n",
    "#         candles = get_schwab_data_for_last_year(ticker, exchange, years=2)  # Fetch 2 years of data\n",
    "#         all_candles_combined.extend(candles)\n",
    "#         print(f\"[{i}/{num_tickers}] {ticker}: {exchange}: Retrieved {len(candles)} candles\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to retrieve {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42308ef",
   "metadata": {},
   "source": [
    "Plot random tickers' analyses from GBQ base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_random_ticker_trades(final_results_dict_gbq, num_tickers_gbq, local_folder=\"local-ticker-data-gbq\", data_source='gbq', num_tickers=3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
