{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d730d50",
   "metadata": {},
   "source": [
    "**Things to talk about with John**\n",
    "- Discretionary futures trading:\n",
    "    - Raw performance\n",
    "    - Good, bad and ugly\n",
    "    - Summary metrics and what they imply\n",
    "    - AI feedback\n",
    "- Stock picking algorithm:\n",
    "    - Scoring metrics weighting\n",
    "    - Rank vs pct_change correlation\n",
    "    - Training weights on pct_change\n",
    "- Programmatic futures trading:\n",
    "    - RSI, MA mean reversion charts\n",
    "    - Likelihood of success and profit expectation\n",
    "    - Searching more parameters\n",
    "    - improving efficiency and memory issues (keeping environment unencumbered by saving to and loading from disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc5803",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Setup</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import schwabdev\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68367a",
   "metadata": {},
   "source": [
    "Set the display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f28b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display options\n",
    "# Set the global float format to 4 decimal places\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "pd.options.display.float_format = '{:,.4f}'.format # Format numerical output to have certain number of decimals\n",
    "# pd.options.display.float_format = None # Reset to default numerical output formatting\n",
    "pd.set_option('display.width', 2000) # Set the display width to a large number\n",
    "pd.set_option('display.max_colwidth', 1000) # Set max column width to a large number\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Displays all columns\n",
    "# pd.set_option('display.max_rows', None) # Displays all rows                             \n",
    "# pd.reset_option('display.max_columns') # Display default abbreviated columns\n",
    "pd.reset_option('display.max_rows') # Display default abbreviated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492839a",
   "metadata": {},
   "source": [
    "Load environment variables from .env file for authentification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57474cdf",
   "metadata": {},
   "source": [
    "Create the client object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2281fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_key = os.getenv('app_key')\n",
    "app_secret = os.getenv('app_secret')\n",
    "callback_url = os.getenv('callback_url')\n",
    "\n",
    "# Print them to verify (avoid printing sensitive info in production)\n",
    "print(f\"App Key: {app_key}\")\n",
    "print(f\"App Secret: {app_secret}\")\n",
    "print(f\"Callback URL: {callback_url}\")\n",
    "\n",
    "# Now proceed to initialize the client\n",
    "client = schwabdev.Client(app_key, app_secret, callback_url)\n",
    "print('Client initialized!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4399e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57de66b2",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Data Preprocessing</h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91932b29",
   "metadata": {},
   "source": [
    "Call in discretionary futures trading performance csv files and display them for inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e031dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows') # Display default abbreviated rows\n",
    "# pd.set_option('display.max_rows', None) # Displays all rows\n",
    "pd.set_option(\"display.max_columns\", None) # Displays all column\n",
    "\n",
    "# Find all Performance*.csv files\n",
    "performance_files = sorted(glob.glob(\"Performance*.csv\"))\n",
    "\n",
    "print(\"Loading files:\")\n",
    "for f in performance_files:\n",
    "    print(f\" - {f}\")\n",
    "\n",
    "# Read and concatenate\n",
    "performance_df = pd.concat(\n",
    "    (pd.read_csv(f) for f in performance_files),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Drop exact duplicate rows\n",
    "performance_df = performance_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "display(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8fbaa5",
   "metadata": {},
   "source": [
    "Convert `pnl` from string format to float as `pnl_usd`. Convert `boughtTimestamp` and `soldTimestamp` from string format to datetime objects as `bought_ts` and `sold_ts` respectively (timezone-naive). Calculate duration of each trade as `duration_td` and `cumulative_pnl` in brokerage-native order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e8e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pnl(pnl_string):\n",
    "    pnl_string = pnl_string.strip()\n",
    "    negative = pnl_string.startswith('$(') or pnl_string.startswith('(')\n",
    "    pnl_string = pnl_string.replace('$', '').replace('(', '').replace(')', '').replace(',', '')\n",
    "    pnl_val = float(pnl_string)\n",
    "    return -pnl_val if negative else pnl_val\n",
    "\n",
    "performance_df['pnl_usd'] = performance_df['pnl'].apply(parse_pnl)\n",
    "\n",
    "performance_df['bought_ts'] = pd.to_datetime(performance_df['boughtTimestamp'], format=\"%m/%d/%Y %H:%M:%S\")\n",
    "performance_df['sold_ts']   = pd.to_datetime(performance_df['soldTimestamp'],  format=\"%m/%d/%Y %H:%M:%S\")\n",
    "performance_df['duration_td'] = performance_df['sold_ts'] - performance_df['bought_ts']\n",
    "performance_df['cumulative_pnl'] = performance_df['pnl_usd'].cumsum()\n",
    "\n",
    "# Drop columns that are no longer needed\n",
    "performance_df = performance_df.drop(columns=['boughtTimestamp', 'soldTimestamp', 'pnl', '_priceFormat', '_priceFormatType', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df['tick_value_usd'] = 12.5\n",
    "performance_df['stop_loss_ticks'] = 40\n",
    "performance_df['take_profit_ticks'] = 40\n",
    "performance_df['stop_loss_usd'] = performance_df['stop_loss_ticks'] * performance_df['tick_value_usd'] * performance_df['qty']\n",
    "performance_df['take_profit_usd'] = performance_df['take_profit_ticks'] * performance_df['tick_value_usd'] * performance_df['qty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45039be7",
   "metadata": {},
   "source": [
    "Calculate long/short and win/loss columns as `trade_direction` and `trade_outcome` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trade_classification(df):\n",
    "    temp = df.copy()\n",
    "\n",
    "    # ----------- Trade Direction -----------\n",
    "    temp['trade_direction'] = np.where(\n",
    "        temp['bought_ts'] < temp['sold_ts'],\n",
    "        'long',\n",
    "        'short'\n",
    "    )\n",
    "\n",
    "    # ----------- Trade Outcome -----------\n",
    "    temp['trade_outcome'] = np.where(\n",
    "        temp['pnl_usd'] > 0,  'win',\n",
    "        np.where(temp['pnl_usd'] < 0, 'loss', 'flat')\n",
    "    )\n",
    "\n",
    "    return temp\n",
    "\n",
    "performance_df = add_trade_classification(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f3204",
   "metadata": {},
   "source": [
    "View columns related to `trade_direction` and `trade_outcome` columns to ensure accurate calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows') # Display default abbreviated rows\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(performance_df[['buyPrice', 'sellPrice', 'bought_ts', 'sold_ts', 'pnl_usd', 'trade_direction', 'trade_outcome']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691bc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79d0663e",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Pull Schwab Futures Data</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649be906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Map your performance symbols to Schwab API symbols ---\n",
    "def map_performance_symbol_to_schwab(symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Map platform/export symbols (e.g., 'ESZ5') to Schwab API symbols (e.g., '/ES').\n",
    "    Extend this mapping as needed for other contracts.\n",
    "    \"\"\"\n",
    "    if symbol.startswith(\"ES\"):\n",
    "        return \"/ES\"\n",
    "    if symbol.startswith(\"NQ\"):\n",
    "        return \"/NQ\"\n",
    "    # Fallback: return as-is, or raise if you prefer strict behavior\n",
    "    return symbol\n",
    "\n",
    "\n",
    "# --- Minute-level Schwab data fetcher using start/end dates ---\n",
    "def get_schwab_minute_data(symbol, start, end, exchange=None, chunk_days=30):\n",
    "    \"\"\"\n",
    "    Fetch 1-minute OHLC candles for a symbol from the Schwab API between start and end (datetime),\n",
    "    chunked by `chunk_days` to respect API limits.\n",
    "    \"\"\"\n",
    "    all_candles = []\n",
    "    window_start = start\n",
    "\n",
    "    while window_start < end:\n",
    "        window_end = min(window_start + timedelta(days=chunk_days), end)\n",
    "\n",
    "        try:\n",
    "            response = client.price_history(\n",
    "                symbol=symbol,\n",
    "                frequencyType='minute',\n",
    "                frequency=5,\n",
    "                startDate=window_start,\n",
    "                endDate=window_end,\n",
    "                needExtendedHoursData=False,\n",
    "            )\n",
    "            json_data = response.json()\n",
    "\n",
    "            # if 'candles' in json_data and json_data['candles']:\n",
    "            for candle in json_data['candles']:\n",
    "                candle[\"ticker\"] = symbol\n",
    "                candle[\"exchange\"] = exchange\n",
    "                all_candles.append(candle)\n",
    "            # else:\n",
    "            #     print(f\"No candles returned for {symbol} in {window_start} → {window_end}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {symbol} in {window_start} → {window_end}: {e}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        window_start = window_end + timedelta(minutes=1)\n",
    "\n",
    "    return all_candles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd1e61",
   "metadata": {},
   "source": [
    "Calculate individual trade time spans for use in developing more specific performance metrics later in the pipeline. Calculate a range of dates that surround all of the trade durations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-row min/max across bought/sold\n",
    "performance_df['row_min_ts'] = performance_df[['bought_ts', 'sold_ts']].min(axis=1)\n",
    "performance_df['row_max_ts'] = performance_df[['bought_ts', 'sold_ts']].max(axis=1)\n",
    "\n",
    "# Per-symbol global min/max\n",
    "symbol_ranges = performance_df.groupby('symbol').agg(\n",
    "    start_ts=('row_min_ts', 'min'),\n",
    "    end_ts=('row_max_ts', 'max')\n",
    ").reset_index()\n",
    "\n",
    "display(symbol_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b6d8a9",
   "metadata": {},
   "source": [
    "Fetching Schwab data for ES that spans the trade data by more than one day in both directions and saving it to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c95648",
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_dfs = []\n",
    "\n",
    "for i, row in symbol_ranges.iterrows():\n",
    "    perf_symbol = row['symbol']\n",
    "    api_symbol = map_performance_symbol_to_schwab(perf_symbol)\n",
    "\n",
    "    start = row['start_ts'] - timedelta(days=1)\n",
    "    end   = row['end_ts']   + timedelta(days=1)\n",
    "\n",
    "    print(f\"Fetching 1-min data for ({api_symbol}) from {start} to {end}...\")\n",
    "\n",
    "    df_tmp = pd.DataFrame(get_schwab_minute_data(api_symbol, start, end))\n",
    "    minute_dfs.append(df_tmp)\n",
    "\n",
    "    print(f\"Fetched {len(df_tmp)} candles for {api_symbol}\")\n",
    "\n",
    "minute_df = pd.concat(minute_dfs, ignore_index=True)\n",
    "minute_df['datetime'] = pd.to_datetime(minute_df['datetime'], unit='ms')\n",
    "minute_df = minute_df.drop(columns=['exchange'])\n",
    "minute_df = minute_df.sort_values(by=['datetime']).reset_index(drop=True)\n",
    "\n",
    "minute_df.to_csv(\"ES_5min_all_contracts.csv\", index=False)\n",
    "print(f\"Saved {len(minute_df)} total candles to ES_5min_all_contracts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bede206",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Displays all columns\n",
    "pd.reset_option('display.max_rows') # Display default abbreviated rows\n",
    "display(minute_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15fc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0245691d",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Macro Trade Performance</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8165d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(df, loss_cap=None, win_cap=None):\n",
    "    \"\"\"\n",
    "    Summarize trade performance with optional PnL capping.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with columns:\n",
    "            - 'trade_direction' ('long'/'short')\n",
    "            - 'trade_outcome'  ('win'/'loss'/'flat')\n",
    "            - 'pnl_usd'        (float)\n",
    "        loss_cap: float or None\n",
    "            If not None, any pnl_usd < loss_cap is set to loss_cap.\n",
    "        win_cap: float or None\n",
    "            If not None, any pnl_usd > win_cap is set to win_cap.\n",
    "\n",
    "    Returns:\n",
    "        dict of summary tables.\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "\n",
    "    # Effective PnL after optional caps (symmetric, no direction bias)\n",
    "    df_temp['pnl_effective'] = df_temp['pnl_usd']\n",
    "\n",
    "    if loss_cap is not None:\n",
    "        df_temp.loc[df_temp['pnl_effective'] < loss_cap, 'pnl_effective'] = loss_cap\n",
    "\n",
    "    if win_cap is not None:\n",
    "        df_temp.loc[df_temp['pnl_effective'] > win_cap, 'pnl_effective'] = win_cap\n",
    "\n",
    "    # --- Counts ---\n",
    "    direction_counts = df_temp['trade_direction'].value_counts()\n",
    "    outcome_counts   = df_temp['trade_outcome'].value_counts()\n",
    "\n",
    "    print(\"Trades by direction:\")\n",
    "    print(direction_counts)\n",
    "    print(\"\\nTrades by outcome:\")\n",
    "    print(outcome_counts)\n",
    "    print()\n",
    "\n",
    "    # --- Direction x Outcome counts ---\n",
    "    combo_counts = pd.crosstab(\n",
    "        df_temp['trade_direction'],\n",
    "        df_temp['trade_outcome']\n",
    "    )\n",
    "    print(\"Count of trades by [direction x outcome]:\")\n",
    "    print(combo_counts)\n",
    "    print()\n",
    "\n",
    "    # --- Nominal PnL by direction (using capped PnL if applied) ---\n",
    "    pnl_by_direction = df_temp.groupby('trade_direction')['pnl_effective'].sum()\n",
    "    print(\"Total PnL by direction (using pnl_effective):\")\n",
    "    print(pnl_by_direction)\n",
    "    print()\n",
    "\n",
    "    # --- Nominal PnL by outcome ---\n",
    "    pnl_by_outcome = df_temp.groupby('trade_outcome')['pnl_effective'].sum()\n",
    "    print(\"Total PnL by outcome (using pnl_effective):\")\n",
    "    print(pnl_by_outcome)\n",
    "    print()\n",
    "\n",
    "    # --- PnL matrix: direction x outcome ---\n",
    "    pnl_combo = pd.pivot_table(\n",
    "        df_temp,\n",
    "        values='pnl_effective',\n",
    "        index='trade_direction',\n",
    "        columns='trade_outcome',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    print(\"Total PnL by [direction x outcome] (using pnl_effective):\")\n",
    "    print(pnl_combo)\n",
    "    print()\n",
    "\n",
    "    # --- Average PnL per trade for each [direction x outcome] ---\n",
    "    avg_pnl_combo = (\n",
    "        df_temp\n",
    "        .groupby(['trade_direction', 'trade_outcome'])['pnl_effective']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    print(\"Average PnL per trade by [direction x outcome] (using pnl_effective):\")\n",
    "    print(avg_pnl_combo)\n",
    "    print()\n",
    "\n",
    "    return {\n",
    "        \"direction_counts\": direction_counts,\n",
    "        \"outcome_counts\": outcome_counts,\n",
    "        \"combo_counts\": combo_counts,\n",
    "        \"pnl_by_direction\": pnl_by_direction,\n",
    "        \"pnl_by_outcome\": pnl_by_outcome,\n",
    "        \"pnl_combo\": pnl_combo,\n",
    "        \"avg_pnl_combo\": avg_pnl_combo,\n",
    "        \"df_with_pnl_effective\": df_temp,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b1dab",
   "metadata": {},
   "source": [
    "Call `summarize_performance` on `performance_df` to get meta data on the raw trade data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_actual = summarize_performance(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec1c2a",
   "metadata": {},
   "source": [
    "**Put a summary of what these trade stats mean about my behavior/psychology as a trader.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef43685",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf82333",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556246f",
   "metadata": {},
   "source": [
    "Call `summarize_performance` on `performance_df` to get meta data on the raw trade data with a filter on negative trades that caps them at -1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cap = -1000\n",
    "summary_capped = summarize_performance(performance_df, loss_cap=loss_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe7bff",
   "metadata": {},
   "source": [
    "**Put a summary of what these trade stats mean about my behavior/psychology as a trader who strictly obeys the risk of loss per trade parameter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b4357",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_pnl(df, sort_by=None, ascending=True, min_pnl=None, max_pnl=None):\n",
    "    \"\"\"\n",
    "    Plot cumulative PnL using an optional capped-risk regime.\n",
    "\n",
    "    This function optionally caps per-trade PnL to simulate honoring\n",
    "    predefined risk limits, allows sorting trades by a chosen column\n",
    "    before aggregation, and plots the resulting cumulative PnL using\n",
    "    the DataFrame index as the x-axis.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame):\n",
    "            Trade-level DataFrame containing at minimum a 'pnl_usd' column.\n",
    "        sort_by (str, optional):\n",
    "            Column name to sort trades by before computing cumulative PnL\n",
    "            (e.g., 'pnl_usd', 'duration_td'). If None, original order is used.\n",
    "        ascending (bool, optional):\n",
    "            Sort order when sort_by is provided. Default is True.\n",
    "        min_pnl (float, optional):\n",
    "            Lower bound for per-trade PnL. Any trade with pnl_usd below this\n",
    "            value is capped to min_pnl. If None, no lower cap is applied.\n",
    "        max_pnl (float, optional):\n",
    "            Upper bound for per-trade PnL. Any trade with pnl_usd above this\n",
    "            value is capped to max_pnl. If None, no upper cap is applied.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "            Displays a matplotlib plot of cumulative PnL under the specified\n",
    "            sorting and risk-capping regime.\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "\n",
    "    # Capped PnL column for \"what if I honored risk rules?\"\n",
    "    df_temp['pnl_capped'] = df_temp['pnl_usd']\n",
    "\n",
    "    if min_pnl is not None:\n",
    "        df_temp['pnl_capped'] = df_temp['pnl_capped'].mask(df_temp['pnl_capped'] < min_pnl, min_pnl)\n",
    "\n",
    "    if max_pnl is not None:\n",
    "        df_temp['pnl_capped'] = df_temp['pnl_capped'].mask(df_temp['pnl_capped'] > max_pnl, max_pnl)\n",
    "\n",
    "    # Optional sorting (uses whatever column you ask for, usually 'pnl_usd' or 'duration_td')\n",
    "    if sort_by is not None:\n",
    "        df_temp = df_temp.sort_values(by=sort_by, ascending=ascending)\n",
    "\n",
    "    # Reset index so x-axis is clean and sequential\n",
    "    df_temp = df_temp.reset_index(drop=True)\n",
    "\n",
    "    # Cumulative PnL under the risk regime (using capped PnL)\n",
    "    df_temp['cumulative_pnl'] = df_temp['pnl_capped'].cumsum()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_temp.index, df_temp['cumulative_pnl'])\n",
    "    plt.title(\n",
    "        \"Cumulative PnL\" +\n",
    "        (f\" (sorted by '{sort_by}')\" if sort_by else \"\")\n",
    "        + (f\" | capped at [{min_pnl if min_pnl is not None else '-∞'}, \"\n",
    "           f\"{max_pnl if max_pnl is not None else '+∞'}]\" if (min_pnl is not None or max_pnl is not None) else \"\")\n",
    "    )\n",
    "    plt.xlabel(\"Trade Number (Index)\")\n",
    "    plt.ylabel(\"Cumulative PnL ($)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa223f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_outlier_filter = -1000\n",
    "upper_outlier_filter = None\n",
    "print(\"Insight: PnL totally wrecked by two heavy days of market weakness. The habit to change would be not to average down when the trade goes against you.\")\n",
    "print(\"Take the loss on the initial bet, don't be arrogant about that decision.\") \n",
    "print(\"Either stay out when action is choppy and negative, or find the nerve and build the skill to sell into weakness.\")\n",
    "plot_cumulative_pnl(performance_df, min_pnl=None, max_pnl=None)\n",
    "\n",
    "print(\"Insight: Had you obeyed a -$1000 per trade risk parameter, your performance would have improved monumentally.\")\n",
    "print(\"You need to review the impact of obeyence of risk parameter on PnL figures. Enlighten yourself on why you did so well between trade 25 and 125.\")\n",
    "print(\"Your attitude, behavioral patterns, and their interactions with the technical/fundamental environments of the time are key to maintaining consistent profitability\")\n",
    "plot_cumulative_pnl(performance_df, min_pnl=lower_outlier_filter, max_pnl=upper_outlier_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64604524",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the worst possible Monte Carlo contingency without PnL filtering.\")\n",
    "plot_cumulative_pnl(performance_df, sort_by='pnl_usd', ascending=True, min_pnl=None, max_pnl=None)\n",
    "\n",
    "print(\"This is the worst possible Monte Carlo contingency under the assumption of strict per trade risk parameter obeyence.\")\n",
    "plot_cumulative_pnl(performance_df, sort_by='pnl_usd', ascending=True, min_pnl=lower_outlier_filter, max_pnl=upper_outlier_filter)\n",
    "\n",
    "print(\"This chart is sorted by trade duration before calculating a temporary cumulative PnL. It may suggest that a certain trade duration marks an inflection point\")\n",
    "print(\"where longer duration past that point makes a trade less likely to be profitable. The implication being that if a trade has been in the red for a long time,\")\n",
    "print(\"it might be advisable to cut loss and look for a new setup.\")\n",
    "plot_cumulative_pnl(performance_df, sort_by='duration_td', ascending=True, min_pnl=None, max_pnl=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37889ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b6ef32c",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Micro Trade Performance</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(performance_df[['bought_ts', 'sold_ts', 'trade_direction', 'trade_outcome']])\n",
    "display(minute_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df['bought_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324df875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_df['trade_mae'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490483e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6faee02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23bf26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99331b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e69eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497923b0",
   "metadata": {},
   "source": [
    "# <h1 style=\"color:red;\">Indicator Calculations</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WMA(series, length):\n",
    "    weights = np.arange(1, length + 1)\n",
    "    return series.rolling(length).apply(lambda x: np.dot(x, weights) / weights.sum(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wmas(df, length1=9, length2=21):\n",
    "    df = df.copy()\n",
    "    df[f'wma_{length1}'] = WMA(df['close'], length1)\n",
    "    df[f'wma_{length2}'] = WMA(df['close'], length2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f67b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_session_vwap(df, session_col='session'):\n",
    "    df = df.copy()\n",
    "\n",
    "    tp = (df['high'] + df['low'] + df['close']) / 3\n",
    "    pv = tp * df['volume']\n",
    "\n",
    "    df['cum_pv'] = pv.groupby(df[session_col]).cumsum()\n",
    "    df['cum_vol'] = df['volume'].groupby(df[session_col]).cumsum()\n",
    "\n",
    "    df['vwap'] = df['cum_pv'] / df['cum_vol']\n",
    "\n",
    "    return df.drop(columns=['cum_pv', 'cum_vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_session_vwap_bands(df, window=30, session_col='session'):\n",
    "    df = df.copy()\n",
    "\n",
    "    tp = (df['high'] + df['low'] + df['close']) / 3\n",
    "    diff = tp - df['vwap']\n",
    "\n",
    "    df['vwap_std'] = diff.groupby(df[session_col]).transform(\n",
    "        lambda x: x.rolling(window).std()\n",
    "    )\n",
    "\n",
    "    df['vwap_upper1'] = df['vwap'] + df['vwap_std']\n",
    "    df['vwap_lower1'] = df['vwap'] - df['vwap_std']\n",
    "    df['vwap_upper2'] = df['vwap'] + 2 * df['vwap_std']\n",
    "    df['vwap_lower2'] = df['vwap'] - 2 * df['vwap_std']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pivots(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['pivot'] = (df['high'] + df['low'] + df['close']) / 3\n",
    "\n",
    "    df['R1'] = 2*df['pivot'] - df['low']\n",
    "    df['S1'] = 2*df['pivot'] - df['high']\n",
    "\n",
    "    df['R2'] = df['pivot'] + (df['high'] - df['low'])\n",
    "    df['S2'] = df['pivot'] - (df['high'] - df['low'])\n",
    "\n",
    "    df['R3'] = df['high'] + 2*(df['pivot'] - df['low'])\n",
    "    df['S3'] = df['low'] - 2*(df['high'] - df['pivot'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_rsi(df, length=14):\n",
    "    df = df.copy()\n",
    "    close = df['close']\n",
    "\n",
    "    delta = close.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "\n",
    "    # Wilder's RSI\n",
    "    avg_gain_w = gain.ewm(alpha=1/length, adjust=False).mean()\n",
    "    avg_loss_w = loss.ewm(alpha=1/length, adjust=False).mean()\n",
    "    rs_w = avg_gain_w / avg_loss_w\n",
    "    df['rsi_wilder'] = 100 - (100 / (1 + rs_w))\n",
    "\n",
    "    # Simple SMA RSI\n",
    "    avg_gain_s = gain.rolling(length).mean()\n",
    "    avg_loss_s = loss.rolling(length).mean()\n",
    "    rs_s = avg_gain_s / avg_loss_s\n",
    "    df['rsi_sma'] = 100 - (100 / (1 + rs_s))\n",
    "\n",
    "    # EMA RSI\n",
    "    avg_gain_e = gain.ewm(span=length, adjust=False).mean()\n",
    "    avg_loss_e = loss.ewm(span=length, adjust=False).mean()\n",
    "    rs_e = avg_gain_e / avg_loss_e\n",
    "    df['rsi_ema'] = 100 - (100 / (1 + rs_e))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wma_signal(df, length=50):\n",
    "    df = df.copy()\n",
    "    df[f'wma_{length}'] = WMA(df['close'], length)\n",
    "    df['price_vs_wma'] = np.sign(df['close'] - df[f'wma_{length}'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_all_indicators(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure datetime sorted\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime')\n",
    "\n",
    "    # Simple session definition (calendar day)\n",
    "    if 'session' not in df.columns:\n",
    "        df['session'] = df['datetime'].dt.date\n",
    "\n",
    "    df = add_session_vwap(df, session_col='session')\n",
    "    df = add_session_vwap_bands(df, window=30, session_col='session')\n",
    "    df = add_wmas(df, length1=9, length2=21)\n",
    "    df = add_pivots(df)\n",
    "    df = add_all_rsi(df, length=14)\n",
    "    df = add_wma_signal(df, length=50)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime is parsed\n",
    "# minute_df['datetime'] = pd.to_datetime(minute_df['datetime'])\n",
    "# minute_df = minute_df.sort_values('datetime')\n",
    "\n",
    "# Apply full indicator suite\n",
    "minute_df = enrich_all_indicators(minute_df)\n",
    "\n",
    "# Save enriched dataset\n",
    "minute_df.to_csv(\"ES_5min_with_indicators.csv\", index=False)\n",
    "\n",
    "print(\"Indicators added. Columns now include:\")\n",
    "print(minute_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409fa42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22ba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ff299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6633925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094a1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90a47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
